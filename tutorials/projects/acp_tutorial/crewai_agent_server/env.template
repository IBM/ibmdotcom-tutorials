## UNCOMMENT THE FIELDS FOR YOUR PREFERRED LLM MODEL PROVIDER AND PROVIDE THE REQUIRED API KEY OR OTHER AUTH REQUIREMENTS.

# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=ollama/llama3:latest

## Change the model field to use your preferred LLM.

# WATSONX_URL=https://us-south.ml.cloud.ibm.com
# WATSONX_APIKEY={your-watsonx-api-key}
# WATSONX_MODEL=watsonx/mistralai/mistral-large
# WATSONX_PROJECT_ID={your-watsonx-project-id}

# AGENTOPS_API_KEY={your-agentops-api-key}