{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a self-RAG agent with IBM granite LLMs: A practical guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Large language models (LLMs)](https://www.ibm.com/think/topics/large-language-models) have remarkable text generation and reasoning abilities but often produce factual inaccuracies or [hallucinations](https://www.ibm.com/think/topics/ai-hallucinations) due to their reliance on internal knowledge. [Retrieval augmented generation](https://www.ibm.com/think/topics/retrieval-augmented-generation) (RAG) based solutions aim to resolve this by injecting external documents into the model’s context. However, traditional [RAG approaches](https://www.ibm.com/think/topics/rag-techniques) retrieve a fixed number of passages regardless of their necessity or quality, leading to redundancy, inefficiency, and inconsistent factual grounding. \n",
    "\n",
    "The self-RAG framework provides a practical solution to this problem. It retrieves information on-demand by using special control tokens that dynamically decide when and how to perform retrieval during generation. Unlike agentic or multi-agent approaches that coordinate multiple models or components, self-RAG is a model-centric framework where a single model manages retrieval, generation, and critique internally. Its self-critique process is a structured step where the model evaluates both its own output and the quality of the retrieved information, allowing it to adapt its retrieval behavior through self-reflection tokens. It combines retrieval, generation and self-critique of its own generations with a single model trained end-to-end that allows more efficient, factual and controllable text generation. This method was originally introduced in the paper on *Self-RAG: Learning to Retrieve, Generate, and Critique Through Self-Reflection* (2024), which explores how [fine-tuning](https://www.ibm.com/think/topics/fine-tuning) LLMs for self-evaluation can improve factual consistency in [natural language processing](https://www.ibm.com/think/topics/natural-language-processing) (NLP) tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How self-RAG works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow of self-RAG is orchestrated by special reflection tokens that the model generates alongside its text output, making the entire inference process dynamic and controllable. When additional information is needed, a single LLM takes on both the retriever and critic roles. A retriever component fetches relevant external passages, and the same LLM then uses reflection tokens to evaluate and refine its own generation during inference. This architecture represents a broader trend in [artificial intelligence](https://www.ibm.com/think/artificial-intelligence) (AI) toward models capable of introspection and dynamic reasoning, bridging advances in prompt engineering and long-form generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. On-demand retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM first generates a retrieval token to determine whether external factual information is necessary for the query. The model skips the remaining retrieval-based steps and continues with standard generation if it concludes that retrieval is not necessary. If the retrieval token is decoded as “yes”, a retriever is called to fetch a set of relevant passages from an external knowledge base. This step makes sure that retrieval occurs when its expected utility is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Passage retrieval and generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If [retrieval](https://www.ibm.com/think/topics/information-retrieval) is required, the retriever fetches relevant passages from an external knowledge base. The LLM simultaneously processes the input and retrieved passages and generates text continuation for each passage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate and reflect on retrieved passages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each segment generated, the model concurrently generates special critique tokens that are embedded directly within the output sequence. These tokens are not separate evaluations, rather they appear as part of the generated sequence and help the model check its own work as it goes:\n",
    "\n",
    "**ISREL (Relevance):** Assesses the usefulness of the retrieved passage.\n",
    "\n",
    "**ISSUP (Support/Factuality):** Evaluates if the generated text segment has whole, partial, or no factual support from the source material.\n",
    "\n",
    "**ISUSE (Utility):** Evaluates the created segment's overall quality, usefulness, and structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During inference, reflection tokens ae used to decide when to retrieve information or not. It enables the model to adjust to different tasks, such as retrieving less for creative activities and more for factual ones. When generating text, reflection tokens help the model in adhering to particular guidelines. They either provide clear boundaries or guide word choice, which makes the model's responses more flexible and appropriate for various contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the self-RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, reflection tokens are inserted into the [training data](https://www.ibm.com/think/topics/training-data) based on evaluations made by the critic model. This approach keeps self-rag training efficient by allowing the model to learn how to judge its own outputs and decide when it actually needs to look up information. Hence, the model becomes better at producing accurate, controlled, and high-quality responses.\n",
    "\n",
    "In the experiment conducted in the research mentioned previously, self-RAG outperforms many standard retrieval-augmented and instruction-tuned baselines across various tasks, including open-domain [question answering](https://www.ibm.com/think/topics/question-answering), reasoning, and fact verification. It improves factuality and citation accuracy by using self-reflection tokens and on-demand retrieval, matching or outperforming OpenAI's models.\n",
    "\n",
    "In this tutorial, you'll learn how to build a robust self-reflective [RAG agent](https://www.ibm.com/think/topics/agentic-rag) by using [IBM Granite® model](https://www.ibm.com/granite) on Watsonx and [LangGraph](https://www.ibm.com/think/topics/langgraph). Similar frameworks and tools, such as [ChatGPT](https://www.ibm.com/think/topics/chatgpt), llama2, LlamaIndex or LangChain, also enable complex RAG flows. However, this tutorial focuses on using the powerful multi-modal models available through IBM. These models understand both text and images as well as its enterprise-grade design supports secure deployment, governance, and scalability. These features make Granite particularly well-suited for building reliable, production-ready RAG systems that can handle complex data and maintain high standards of trust and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Building a self-RAG query agent over multi-modal documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to build a self-RAG agent designed to answer complex, multi-faceted queries over internal knowledge bases that include both text and visual data. This agent will analyze PDF documents including technical guidelines and survey data. It will guide you to implement the self-RAG algorithm, which:\n",
    "\n",
    "**Creates a multi-modal knowledge base:** Uses a language model (granite-3-3-8b-instruct) and vision LLM (granite-vision-3.3-2B) to extract text and images from PDFs, generate descriptive captions, and create embeddings for both text and image data to enable semantic retrieval.\n",
    "\n",
    "**Generates and reflects:** It creates an answer segment, adds reflection tokens (such ISREL, ISSUP, and ISUSE) and evaluates its own output quality and factual accuracy.\n",
    "\n",
    "**Executes self-correction:** The LangGraph workflow extends the standard self-RAG approach by using a critique score derived from reflection tokens to guide its next steps. When the score is low, the agent requests stronger context and retrieves more relevant information before generating the next segment, helping produce a higher-quality final output.\n",
    "\n",
    "**Provides segmented answers:** Provides thorough and traceable responses by generating complex answers in a sequence of factually validated chunks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need an [IBM Cloud® account](https://cloud.ibm.com/registration?utm_source=ibm_developer&utm_content=in_content_link&utm_id=tutorials_awb-implement-xgboost-in-python&cm_sp=ibmdev-_-developer-_-trial) to create a [watsonx.ai®](https://www.ibm.com/products/watsonx-ai?utm_source=ibm_developer&utm_content=in_content_link&utm_id=tutorials_awb-implement-xgboost-in-python&cm_sp=ibmdev-_-developer-_-product) project. Ensure that you have access to both your watsonx API Key and Project ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Set up your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can choose from several tools, this tutorial walks you through how to set up an IBM account by using a Jupyter Notebook.\n",
    "\n",
    "1.\tLog in to [watsonx.ai](https://dataplatform.cloud.ibm.com/registration/stepone?context=wx&apps=all) by using your IBM Cloud account.\n",
    "\n",
    "2.\tCreate a [watsonx.ai project](https://www.ibm.com/docs/en/watsonx/saas?topic=projects-creating-project). You can get your project ID from within your project. Click the Manage tab.Then, copy the project ID from the Details section of the General page. You need this ID for this tutorial.\n",
    "\n",
    "3.\tCreate a [Jupyter Notebook](https://www.ibm.com/docs/en/watsonx/saas?topic=editor-creating-managing-notebooks).\n",
    "\n",
    "This step opens a notebook environment where you can copy the code from this tutorial. Alternatively, you can download this notebook to your local system and upload it to your watsonx.ai project as an asset. To view more Granite tutorials, check out the [IBM Granite Community](https://github.com/ibm-granite-community). This tutorial is also available on [GitHub](https://github.com/IBM/ibmdotcom-tutorials).\n",
    "\n",
    "**Note:** You can run the multi-modal self-RAG tutorial entirely on a local CPU system. This is achievable by adapting the setup to use local resources instead of remote cloud services. You can initialize the Granite instruct model (the 3.2 2B version) directly from Hugging Face using the appropriate `transformers` steps. For data handling, save your PDF files directly on your local system and easily read them into your Jupyter Notebook environment using their local file path, completely bypassing the need for IBM Cloud Object Storage. To handle the complex reasoning and self-critique, the larger remote Granite 3.3-8B model can be replaced by a powerful open-source LLM hosted locally using a dedicated server setup. This setup requires installing specific local Python dependencies, such as `langgraph`, `faiss-cpu`, `sentence-transformers`, and `pymupdf` for the vector store, RAG logic, embeddings, and PDF parsing, respectively. Models can be configured for efficient CPU operation by explicitly setting the device to \"cpu\" and adjusting the floating-point data type to manage memory usage and prevent crashes common with large models on typical desktop hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Set up watsonx.ai runtime service and API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tCreate a [watsonx.ai Runtime](https://cloud.ibm.com/catalog/services/watsonxai-runtime) service instance (choose the Lite plan, which is a free instance).\n",
    "\n",
    "2.\tGenerate an application programming interface [(API) Key](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-authentication.html).\n",
    "\n",
    "3.\tAssociate the watsonx.ai Runtime service to the project that you created in [watsonx.ai](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html?context=cpdaas).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Installation of the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build and orchestrate this multi-modal self-reflective RAG agent, we require a comprehensive set of libraries. Install `langgraph` to define the core state machine that orchestrates the self-correction loop based on critique ratings. For integrating IBM Granite LLMs and [embeddings](https://www.ibm.com/think/topics/embedding) from the Watsonx platform, install `langchain-ibm` and `ibm-watsonx-ai`. For quick retrieval, install `faiss-cpu` that offers indexing for the vector store. We use deep learning libraries like `torch` and the [hugging face](https://www.ibm.com/think/topics/hugging-face) `transformers` library to load and run the granite-vision-3.3-2B model. To extract and process the text and images from our PDF documents, `pillow` and `pymupdf` are essential. Lastly, to access raw data from cloud object storage, `ibm-cos-sdk` is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4d576e6-39ba-4803-b355-6b275d9ffe52",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers>=4.50.0\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: huggingface_hub>=0.26.2 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (0.29.2)\n",
      "Collecting huggingface_hub>=0.26.2\n",
      "  Downloading huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (2.1.2)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (0.16.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langgraph in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (0.2.40)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (10.3.0)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (4.66.4)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pydantic in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (2.11.9)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: langchain-ibm in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (0.3.18)\n",
      "Collecting langchain-ibm\n",
      "  Downloading langchain_ibm-1.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: ibm-watsonx-ai in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (1.4.2)\n",
      "Collecting ibm-watsonx-ai\n",
      "  Downloading ibm_watsonx_ai-1.4.5-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (2.14.2)\n",
      "Collecting ibm-cos-sdk\n",
      "  Downloading ibm_cos_sdk-2.14.3.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sentence-transformers in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (2.3.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from transformers>=4.50.0) (3.13.1)\n",
      "Collecting huggingface_hub>=0.26.2\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from transformers>=4.50.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from transformers>=4.50.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from transformers>=4.50.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from transformers>=4.50.0) (2023.10.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.50.0)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.50.0)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from huggingface_hub>=0.26.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from huggingface_hub>=0.26.2) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.26.2)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch)\n",
      "  Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langgraph) (0.3.76)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langgraph) (3.5.0)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from pydantic) (0.6.0)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from ibm-watsonx-ai) (2.1.4)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.8.10)\n",
      "Requirement already satisfied: cachetools in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from ibm-watsonx-ai) (5.3.3)\n",
      "Collecting ibm-cos-sdk-core==2.14.3 (from ibm-cos-sdk)\n",
      "  Downloading ibm_cos_sdk_core-2.14.3.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.14.3 (from ibm-cos-sdk)\n",
      "  Downloading ibm_cos_sdk_s3transfer-2.14.3.tar.gz (139 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from ibm-cos-sdk) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (0.4.31)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (8.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.9.0->ibm-cos-sdk-core==2.14.3->ibm-cos-sdk) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT24.1-CUDA/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m189.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m152.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m166.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m170.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m169.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m147.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m139.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m156.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m168.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m178.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.9.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m153.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m211.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m145.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m137.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_ibm-1.0.0-py3-none-any.whl (49 kB)\n",
      "Downloading ibm_watsonx_ai-1.4.5-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading ormsgpack-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
      "\u001b[33m  DEPRECATION: Building 'ibm-cos-sdk' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ibm-cos-sdk'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.14.3-py3-none-any.whl size=77324 sha256=c516e4776629432b68631e150d6c206052fccfe15c944526609c05298400c6e1\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/56/fa/85/9a1004ed234750540a7a90f34000bc1208e723f3613eaafc2b\n",
      "\u001b[33m  DEPRECATION: Building 'ibm-cos-sdk-core' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ibm-cos-sdk-core'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.14.3-py3-none-any.whl size=662207 sha256=473d3a41154f32c13b49e4b7496f0da69f9f48cdd0b48674fb9bf6c12e453f32\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/96/25/ac/fa87dd4aeda7eba0f3e7e891c52f9c92c8b2ea49963119d9df\n",
      "\u001b[33m  DEPRECATION: Building 'ibm-cos-sdk-s3transfer' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'ibm-cos-sdk-s3transfer'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.14.3-py3-none-any.whl size=90309 sha256=0f74440d13ca8609cb935d81a70073db01b25617caa67df208aa9c34574ade9f\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/c4/03/6f/e85bbf1471a809e7892239f69458cef2cd69ee38fb543339c8\n",
      "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
      "Installing collected packages: nvidia-cusparselt-cu12, typing-inspection, triton, tqdm, sympy, safetensors, pymupdf, pydantic-core, Pillow, ormsgpack, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, faiss-cpu, pydantic, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, ibm-cos-sdk-core, huggingface_hub, tokenizers, nvidia-cusolver-cu12, langgraph-sdk, ibm-cos-sdk-s3transfer, transformers, torch, langchain-core, ibm-cos-sdk, torchvision, torchaudio, sentence-transformers, langgraph-checkpoint, ibm-watsonx-ai, langgraph-prebuilt, langchain-ibm, langgraph\n",
      "\u001b[2K  Attempting uninstall: typing-inspection━━━━━━━\u001b[0m \u001b[32m 0/44\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.0/44\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.0:━━━\u001b[0m \u001b[32m 0/44\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.0 0/44\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: tqdm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/44\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: tqdm 4.66.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/44\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling tqdm-4.66.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/44\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.66.4━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/44\u001b[0m [tqdm]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/44\u001b[0m [tqdm]\n",
      "\u001b[2K    Found existing installation: sympy 1.12━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/44\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling sympy-1.12:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/44\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/44\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: safetensors━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/44\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: safetensors 0.4.2━━━━━━━━━━━━\u001b[0m \u001b[32m 4/44\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling safetensors-0.4.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/44\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled safetensors-0.4.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/44\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.33.2━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.33.2:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.33.2━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K  Attempting uninstall: Pillow━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K    Found existing installation: pillow 10.3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K    Uninstalling pillow-10.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K      Successfully uninstalled pillow-10.3.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/44\u001b[0m [pymupdf]\n",
      "\u001b[2K  Attempting uninstall: pydantic[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [faiss-cpu]las-cu12]u12]2]\n",
      "\u001b[2K    Found existing installation: pydantic 2.11.9━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [faiss-cpu]\n",
      "\u001b[2K    Uninstalling pydantic-2.11.9:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/44\u001b[0m [faiss-cpu]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.11.9m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/44\u001b[0m [pydantic]\n",
      "\u001b[2K  Attempting uninstall: ibm-cos-sdk-core\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/44\u001b[0m [nvidia-cudnn-cu12]12]\n",
      "\u001b[2K    Found existing installation: ibm-cos-sdk-core 2.14.2━━━━━━\u001b[0m \u001b[32m25/44\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling ibm-cos-sdk-core-2.14.2:[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/44\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled ibm-cos-sdk-core-2.14.2━━━━━━━━━━━━\u001b[0m \u001b[32m26/44\u001b[0m [ibm-cos-sdk-core]\n",
      "\u001b[2K  Attempting uninstall: huggingface_hubm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/44\u001b[0m [ibm-cos-sdk-core]\n",
      "\u001b[2K    Found existing installation: huggingface_hub 0.29.2━━━━━━━\u001b[0m \u001b[32m26/44\u001b[0m [ibm-cos-sdk-core]\n",
      "\u001b[2K    Uninstalling huggingface_hub-0.29.2:m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/44\u001b[0m [ibm-cos-sdk-core]\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-0.29.2━━━━━━━━━\u001b[0m \u001b[32m26/44\u001b[0m [ibm-cos-sdk-core]\n",
      "\u001b[2K  Attempting uninstall: tokenizers0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/44\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.15.1━━━━━━━━━━━━\u001b[0m \u001b[32m27/44\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling tokenizers-0.15.1:1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/44\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.15.1[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/44\u001b[0m [tokenizers]]\n",
      "\u001b[2K  Attempting uninstall: langgraph-sdkm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: langgraph-sdk 0.1.51━━━━━━━━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling langgraph-sdk-0.1.51:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled langgraph-sdk-0.1.51━━━━━━━━━━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: ibm-cos-sdk-s3transfer90m━━━━━━━━━━━━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: ibm-cos-sdk-s3transfer 2.14.2\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling ibm-cos-sdk-s3transfer-2.14.2:0m━━━━━━━━━━━━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled ibm-cos-sdk-s3transfer-2.14.2━━\u001b[0m \u001b[32m29/44\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: transformers\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m31/44\u001b[0m [ibm-cos-sdk-s3transfer]\n",
      "\u001b[2K    Found existing installation: transformers 4.37.2━━━━━━━━━━\u001b[0m \u001b[32m31/44\u001b[0m [ibm-cos-sdk-s3transfer]\n",
      "\u001b[2K    Uninstalling transformers-4.37.2:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m31/44\u001b[0m [ibm-cos-sdk-s3transfer]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.37.2m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m32/44\u001b[0m [transformers]nsfer]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m32/44\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torch 2.1.2[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m32/44\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torch-2.1.2:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m32/44\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled torch-2.1.2\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m33/44\u001b[0m [torch]rs]\n",
      "\u001b[2K  Attempting uninstall: langchain-core\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m33/44\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.76━━━━━━━━\u001b[0m \u001b[32m33/44\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.76:[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m33/44\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.76m━━━━━━━━━\u001b[0m \u001b[32m33/44\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: ibm-cos-sdk━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: ibm-cos-sdk 2.14.20m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling ibm-cos-sdk-2.14.2:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled ibm-cos-sdk-2.14.2[90m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: torchvision[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: torchvision 0.16.20m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling torchvision-0.16.2:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m34/44\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.16.2╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m36/44\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: sentence-transformers\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m37/44\u001b[0m [torchaudio]]\n",
      "\u001b[2K    Found existing installation: sentence-transformers 2.3.1━━\u001b[0m \u001b[32m37/44\u001b[0m [torchaudio]\n",
      "\u001b[2K    Uninstalling sentence-transformers-2.3.1:m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m37/44\u001b[0m [torchaudio]\n",
      "\u001b[2K      Successfully uninstalled sentence-transformers-2.3.1━━━━\u001b[0m \u001b[32m37/44\u001b[0m [torchaudio]\n",
      "\u001b[2K  Attempting uninstall: langgraph-checkpoint0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m38/44\u001b[0m [sentence-transformers]\n",
      "\u001b[2K    Found existing installation: langgraph-checkpoint 2.0.990m━━━━\u001b[0m \u001b[32m39/44\u001b[0m [langgraph-checkpoint]\n",
      "\u001b[2K    Uninstalling langgraph-checkpoint-2.0.9:[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m39/44\u001b[0m [langgraph-checkpoint]\n",
      "\u001b[2K      Successfully uninstalled langgraph-checkpoint-2.0.9m━━━━\u001b[0m \u001b[32m39/44\u001b[0m [langgraph-checkpoint]\n",
      "\u001b[2K  Attempting uninstall: ibm-watsonx-ai━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m39/44\u001b[0m [langgraph-checkpoint]\n",
      "\u001b[2K    Found existing installation: ibm_watsonx_ai 1.4.2\u001b[90m━━━━\u001b[0m \u001b[32m39/44\u001b[0m [langgraph-checkpoint]\n",
      "\u001b[2K    Uninstalling ibm_watsonx_ai-1.4.2:━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m39/44\u001b[0m [langgraph-checkpoint]\n",
      "\u001b[2K      Successfully uninstalled ibm_watsonx_ai-1.4.20m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m40/44\u001b[0m [ibm-watsonx-ai]t]\n",
      "\u001b[2K  Attempting uninstall: langchain-ibm━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m40/44\u001b[0m [ibm-watsonx-ai]\n",
      "\u001b[2K    Found existing installation: langchain-ibm 0.3.18m\u001b[90m━━━\u001b[0m \u001b[32m40/44\u001b[0m [ibm-watsonx-ai]\n",
      "\u001b[2K    Uninstalling langchain-ibm-0.3.18:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m40/44\u001b[0m [ibm-watsonx-ai]\n",
      "\u001b[2K      Successfully uninstalled langchain-ibm-0.3.18[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m42/44\u001b[0m [langchain-ibm]\n",
      "\u001b[2K  Attempting uninstall: langgraph━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m42/44\u001b[0m [langchain-ibm]\n",
      "\u001b[2K    Found existing installation: langgraph 0.2.400m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m42/44\u001b[0m [langchain-ibm]\n",
      "\u001b[2K    Uninstalling langgraph-0.2.40:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m42/44\u001b[0m [langchain-ibm]\n",
      "\u001b[2K      Successfully uninstalled langgraph-0.2.40[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m42/44\u001b[0m [langchain-ibm]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/44\u001b[0m [langgraph]anggraph]hain-ibm]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "caikit-nlp 0.4.9 requires sentence-transformers<2.4.0,>=2.3.1, but you have sentence-transformers 5.1.2 which is incompatible.\n",
      "caikit-nlp 0.4.9 requires torch<2.3.0,>=2.0.1, but you have torch 2.9.0 which is incompatible.\n",
      "langchain-chroma 0.1.4 requires langchain-core<0.4,>=0.1.40; python_version >= \"3.9\", but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain-elasticsearch 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain-milvus 0.1.8 requires langchain-core<0.4,>=0.2.38, but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain-mcp-adapters 0.1.7 requires langchain-core<0.4,>=0.3.36, but you have langchain-core 1.0.4 which is incompatible.\n",
      "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-12.0.0 faiss-cpu-1.12.0 hf-xet-1.2.0 huggingface_hub-0.36.0 ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm-watsonx-ai-1.4.5 langchain-core-1.0.4 langchain-ibm-1.0.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 ormsgpack-1.12.0 pydantic-2.12.4 pydantic-core-2.41.5 pymupdf-1.26.6 safetensors-0.6.2 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 tqdm-4.67.1 transformers-4.57.1 triton-3.5.0 typing-inspection-0.4.2\n",
      "Required packages installed.\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "\n",
    "!pip install -U \"transformers>=4.50.0\" \"huggingface_hub>=0.26.2\" \\\n",
    "  torch torchvision torchaudio \\\n",
    "  langgraph faiss-cpu Pillow requests tqdm pymupdf pydantic \\\n",
    "  langchain-ibm ibm-watsonx-ai ibm-cos-sdk sentence-transformers\n",
    "\n",
    "print(\"Required packages installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** No GPU is required, but execution can be slower on CPU-based systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import all the necessary modules to set up the fundamental tools for managing the multi-modal components, processing documents, coordinating the RAG [workflow](https://www.ibm.com/think/topics/agentic-workflows), and connecting to IBM watsonx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e02b99b-e5eb-4bfd-9b01-a22d785e6d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core libraries imported successfully.\n",
      "PyTorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries Import\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import torch\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, TypedDict\n",
    "import gc\n",
    "\n",
    "# LangGraph / LangChain Core\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ibm import WatsonxLLM, WatsonxEmbeddings\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "\n",
    "# Vector store + text utilities\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# General utils\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import fitz # PyMuPDF for PDFs\n",
    "import numpy as np\n",
    "import io # Ensure io is imported\n",
    "\n",
    "print(\"Core libraries imported successfully.\")\n",
    "# Set up device for Vision Model\n",
    "HF_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"PyTorch device: {HF_DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-modal context:** This tutorial uses a vision model and libraries like `fitz` to process both text and visual data into a unified context. This surpasses simple text-based RAG by enabling the agent to retrieve richer information and provide highly accurate answers derived from complex documents.\n",
    "\n",
    "**Self-correction loop:** The system utilizes LangGraph (StateGraph) to build a self-reflective RAG agent. This allows the LLM to critique its own output for relevance and accuracy, and then automatically initiate a correction cycle by querying the vector store or refining the prompt, minimizing hallucinations.\n",
    "\n",
    "**Production-ready integration:** The tutorial demonstrates a high-performance stack by integrating enterprise LLMs (such as Granite) accessed via an external [API](https://www.ibm.com/think/topics/api) (or Hugging Face, depending on the setup) with efficient vector storage (FAISS) and streamlined RAG logic, proving its viability for real-world deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Load watsonx credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step prepares your environment to securely connect to the IBM watsonx platform, allowing you to utilize the hosted granite LLMs and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb715357-1a94-494e-8036-fdc70cee67fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Watsonx API Key:  ········\n",
      "Enter Watsonx Project ID:  4d09cb34-ffa1-4097-be01-79e1ac1f5173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Watsonx credentials loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Watsonx Credentials\n",
    "\n",
    "WML_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
    "\n",
    "# Securely input Watsonx credentials\n",
    "WML_API_KEY = getpass.getpass(\"Enter Watsonx API Key: \")\n",
    "PROJECT_ID = input(\"Enter Watsonx Project ID: \")\n",
    "\n",
    "# Set environment variables for langchain-ibm\n",
    "os.environ[\"WATSONX_APIKEY\"] = WML_API_KEY\n",
    "os.environ[\"WATSONX_PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "print(\" Watsonx credentials loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Initialize models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This critical step configures the three distinct models required for our multi-modal self-RAG agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6808622c-eadf-43ec-ba7e-99be046c59e9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 06:03:48.844314: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-11 06:03:48.844348: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-11 06:03:48.844355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite-3-3-8B-Instruct initialized for reasoning, QA, and self-critique.\n",
      "Granite-embedding-278m-multilingual initialized for retrieval.\n",
      "Loading Granite Vision model in Bfloat16 for memory efficiency...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7088a46b4eb94a1f902854ed118f9c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/174 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13faccf83e714d66a11bee5d87918efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dc324d70444cbebdf6e58f5facbb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b634b6b4f7dd414a96be017e82040bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929295b7c98b46e393fcc77809e96f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739f67cc39a24ad9a6180b97839ec324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec8d5c5b09546e098963ae5c16ec228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6671f720534466e94e77f6317793e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/107 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14697cb6689549939fc0254eaee754f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2a0eb5c749475fbcb43452ebdf5789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13631fc44a384140979285d8efc9b07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb9aa54122e4ad695d8317b0bf77e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157a9450a98b44b08220a428726afee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0447f5939ba745f1822cb196443d28bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/952M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0b45b1406d4c3cb42e8a9cc297f9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172e70ec7adc42c28481200cbfb9d47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granite-Vision-3.3-2B initialized successfully with Bfloat16.\n",
      "Device available: cuda\n",
      "All Watsonx + Vision models ready.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Models\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# LLM: Granite-3-3-8B-Instruct (Generator & Critic)\n",
    "qa_llm = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-3-3-8b-instruct\",\n",
    "    url=WML_URL,\n",
    "    apikey=WML_API_KEY,\n",
    "    project_id=PROJECT_ID,\n",
    "    params={\n",
    "        GenTextParamsMetaNames.MAX_NEW_TOKENS: 512, \n",
    "        GenTextParamsMetaNames.TEMPERATURE: 0.1,   \n",
    "        GenTextParamsMetaNames.TOP_P: 0.9,\n",
    "        GenTextParamsMetaNames.REPETITION_PENALTY: 1.05,\n",
    "    },\n",
    ")\n",
    "print(\"Granite-3-3-8B-Instruct initialized for reasoning, QA, and self-critique.\")\n",
    "\n",
    "# Embedding Model: Granite-embedding-278m-multilingual\n",
    "embeddings_model = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/granite-embedding-278m-multilingual\",\n",
    "    url=WML_URL,\n",
    "    apikey=WML_API_KEY,\n",
    "    project_id=PROJECT_ID,\n",
    ")\n",
    "print(\"Granite-embedding-278m-multilingual initialized for retrieval.\")\n",
    "\n",
    "# Vision Model: Granite-Vision-3.3-2B\n",
    "try:\n",
    "    print(\"Loading Granite Vision model in Bfloat16 for memory efficiency...\")\n",
    "    vision_model_id = \"ibm-granite/granite-vision-3.3-2b\"\n",
    "\n",
    "    hf_processor = AutoProcessor.from_pretrained(vision_model_id)\n",
    "    \n",
    "    \n",
    "    hf_vision_model = AutoModelForVision2Seq.from_pretrained(\n",
    "        vision_model_id, \n",
    "        torch_dtype=torch.bfloat16 # <--- Saves ~50% VRAM on model weights\n",
    "    ).to(HF_DEVICE)\n",
    "    hf_vision_model.eval()\n",
    "\n",
    "    print(\"Granite-Vision-3.3-2B initialized successfully with Bfloat16.\")\n",
    "except Exception as e:\n",
    "    print(f\"Vision model load failed: {e}\")\n",
    "\n",
    "print(f\"Device available: {HF_DEVICE}\")\n",
    "print(\"All Watsonx + Vision models ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration will:\n",
    "\n",
    "Initialize the **granite-3-3-8B-instruct** model to function as both the primary generator and the self-critic by producing the reflection tokens (ISREL, ISSUP, and ISUSE).  For the self-critique loop, the parameters are optimized for factual, deterministic, and stable answers.\n",
    "\n",
    "Initialize the **granite-embedding-278m-multilingual** model. This model generates the textual embeddings essential for efficient semantic search and retrieval in the FAISS vector store.\n",
    "\n",
    "Load the **granite-vision-3.3-2B** model locally using the transformers library. This model creates text captions for images extracted from PDF documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. PDF data retrieval from cloud object storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step focuses on securely retrieving the source dataset from IBM cloud object storage into the memory of your execution environment. This is necessary before any text splitting or multi-modal analysis can begin. We have uploaded two PDF files to the database for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec86ad8e-bbaf-414c-b933-2d0a815924a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Downloading ICH_E6(R3)_Guideline.pdf ...\n",
      " Finished downloading ICH_E6(R3)_Guideline.pdf (0.79 MB)\n",
      " Downloading inspection_survey.pdf ...\n",
      " Finished downloading inspection_survey.pdf (2.22 MB)\n",
      " All 2 PDFs downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# PDF Text Extraction\n",
    "import io\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='your_api_key_id',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/identity/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.direct.us-south.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'bucket_key'\n",
    "pdf_keys = [\n",
    "    'ICH_E6(R3)_Guideline.pdf',\n",
    "    'inspection_survey.pdf'\n",
    "]\n",
    "\n",
    "def read_cos_pdf(bucket, key):\n",
    "    \"\"\"Read a PDF from IBM COS into bytes (streamed in chunks).\"\"\"\n",
    "    print(f\" Downloading {key} ...\")\n",
    "    response = cos_client.get_object(Bucket=bucket, Key=key)\n",
    "    body = response['Body']\n",
    "    data = io.BytesIO()\n",
    "    while True:\n",
    "        chunk = body.read(10 * 1024 * 1024)  # 10 MB chunks\n",
    "        if not chunk:\n",
    "            break\n",
    "        data.write(chunk)\n",
    "    data.seek(0)\n",
    "    print(f\" Finished downloading {key} ({data.getbuffer().nbytes / (1024*1024):.2f} MB)\")\n",
    "    return data.read()\n",
    "\n",
    "# Loop through all PDFs and download\n",
    "pdf_files = {}\n",
    "for key in pdf_keys:\n",
    "    pdf_files[key] = read_cos_pdf(bucket, key)\n",
    "\n",
    "print(f\" All {len(pdf_files)} PDFs downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Multi-modal PDF parsing and captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is crucial for transforming our raw PDF documents into a multi-modal, searchable knowledge base for the self-RAG agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11e123f4-740d-43d2-bccd-aa01c048478d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cache file not found. Running Multi-Modal PDF Parsing and Captioning...\n",
      "\n",
      "Processing ICH_E6(R3)_Guideline.pdf...\n",
      "\n",
      "Processing inspection_survey.pdf...\n",
      "  -> inspection_survey.pdf identified as image-containing. Beginning image extraction...\n",
      "    -> Captioning image 1 on page 1...\n",
      "    -> Captioning image 2 on page 1...\n",
      "    -> Captioning image 3 on page 1...\n",
      "    -> Captioning image 4 on page 1...\n",
      "    -> Captioning image 5 on page 1...\n",
      "    -> Captioning image 6 on page 1...\n",
      "    -> Captioning image 7 on page 1...\n",
      "    -> Captioning image 8 on page 1...\n",
      "    -> Captioning image 9 on page 1...\n",
      "    -> Captioning image 1 on page 2...\n",
      "    -> Captioning image 2 on page 2...\n",
      "    -> Captioning image 3 on page 2...\n",
      "    -> Captioning image 4 on page 2...\n",
      "    -> Captioning image 1 on page 3...\n",
      "    -> Captioning image 2 on page 3...\n",
      "    -> Captioning image 3 on page 3...\n",
      "    -> Captioning image 1 on page 4...\n",
      "    -> Captioning image 2 on page 4...\n",
      "    -> Captioning image 3 on page 4...\n",
      "    -> Captioning image 4 on page 4...\n",
      "    -> Captioning image 1 on page 5...\n",
      "    -> Captioning image 2 on page 5...\n",
      "    -> Captioning image 3 on page 5...\n",
      "    -> Captioning image 1 on page 6...\n",
      "    -> Captioning image 2 on page 6...\n",
      "    -> Captioning image 3 on page 6...\n",
      "    -> Captioning image 4 on page 6...\n",
      "    -> Captioning image 1 on page 7...\n",
      "    -> Captioning image 2 on page 7...\n",
      "    -> Captioning image 3 on page 7...\n",
      "    -> Captioning image 4 on page 7...\n",
      "    -> Captioning image 5 on page 7...\n",
      "    -> Captioning image 1 on page 8...\n",
      "    -> Captioning image 2 on page 8...\n",
      "    -> Captioning image 3 on page 8...\n",
      "    -> Captioning image 4 on page 8...\n",
      "    -> Captioning image 5 on page 8...\n",
      "    -> Captioning image 1 on page 9...\n",
      "    -> Captioning image 2 on page 9...\n",
      "    -> Captioning image 3 on page 9...\n",
      "    -> Captioning image 4 on page 9...\n",
      "    -> Captioning image 1 on page 10...\n",
      "    -> Captioning image 2 on page 10...\n",
      "    -> Captioning image 1 on page 11...\n",
      "    -> Captioning image 2 on page 11...\n",
      "    -> Captioning image 1 on page 12...\n",
      "    -> Captioning image 2 on page 12...\n",
      "    -> Captioning image 3 on page 12...\n",
      "    -> Captioning image 4 on page 12...\n",
      "    -> Captioning image 1 on page 13...\n",
      "    -> Captioning image 2 on page 13...\n",
      "    -> Captioning image 3 on page 13...\n",
      "    -> Captioning image 1 on page 14...\n",
      "    -> Captioning image 2 on page 14...\n",
      "    -> Captioning image 3 on page 14...\n",
      "    -> Captioning image 4 on page 14...\n",
      "    -> Captioning image 1 on page 15...\n",
      "    -> Captioning image 2 on page 15...\n",
      "    -> Captioning image 3 on page 15...\n",
      "    -> Captioning image 4 on page 15...\n",
      "    -> Captioning image 5 on page 15...\n",
      "    -> Captioning image 1 on page 16...\n",
      "    -> Captioning image 2 on page 16...\n",
      "    -> Captioning image 3 on page 16...\n",
      "    -> Captioning image 1 on page 17...\n",
      "    -> Captioning image 2 on page 17...\n",
      "    -> Captioning image 1 on page 18...\n",
      "    -> Captioning image 2 on page 18...\n",
      "    -> Captioning image 3 on page 18...\n",
      "    -> Captioning image 4 on page 18...\n",
      "    -> Captioning image 1 on page 19...\n",
      "    -> Captioning image 2 on page 19...\n",
      "    -> Captioning image 1 on page 20...\n",
      "    -> Captioning image 2 on page 20...\n",
      "    -> Captioning image 3 on page 20...\n",
      "    -> Captioning image 1 on page 21...\n",
      "    -> Captioning image 2 on page 21...\n",
      "    -> Captioning image 3 on page 21...\n",
      "    -> Captioning image 4 on page 21...\n",
      "    -> Captioning image 5 on page 21...\n",
      "    -> Captioning image 6 on page 21...\n",
      "    -> Captioning image 7 on page 21...\n",
      "    -> Captioning image 8 on page 21...\n",
      "    -> Captioning image 1 on page 22...\n",
      "    -> Captioning image 2 on page 22...\n",
      "    -> Captioning image 3 on page 22...\n",
      "    -> Captioning image 1 on page 23...\n",
      "    -> Captioning image 2 on page 23...\n",
      "    -> Captioning image 3 on page 23...\n",
      "    -> Captioning image 1 on page 24...\n",
      "    -> Captioning image 2 on page 24...\n",
      "    -> Captioning image 1 on page 25...\n",
      "    -> Captioning image 2 on page 25...\n",
      "    -> Captioning image 3 on page 25...\n",
      "    -> Captioning image 1 on page 26...\n",
      "    -> Captioning image 2 on page 26...\n",
      "    -> Captioning image 3 on page 26...\n",
      "    -> Captioning image 4 on page 26...\n",
      "    -> Captioning image 5 on page 26...\n",
      "    -> Captioning image 6 on page 26...\n",
      "    -> Captioning image 1 on page 27...\n",
      "    -> Captioning image 2 on page 27...\n",
      "    -> Captioning image 3 on page 27...\n",
      "    -> Captioning image 4 on page 27...\n",
      "    -> Captioning image 5 on page 27...\n",
      "    -> Captioning image 1 on page 28...\n",
      "    -> Captioning image 2 on page 28...\n",
      "    -> Captioning image 1 on page 29...\n",
      "    -> Captioning image 2 on page 29...\n",
      "    -> Captioning image 3 on page 29...\n",
      "    -> Captioning image 4 on page 29...\n",
      "    -> Captioning image 5 on page 29...\n",
      "    -> Captioning image 6 on page 29...\n",
      "    -> Captioning image 1 on page 30...\n",
      "    -> Captioning image 2 on page 30...\n",
      "    -> Captioning image 1 on page 31...\n",
      "    -> Captioning image 2 on page 31...\n",
      "    -> Captioning image 3 on page 31...\n",
      "    -> Captioning image 4 on page 31...\n",
      "    -> Captioning image 5 on page 31...\n",
      "    -> Captioning image 6 on page 31...\n",
      "    -> Captioning image 1 on page 32...\n",
      "    -> Captioning image 2 on page 32...\n",
      "    -> Captioning image 3 on page 32...\n",
      "    -> Captioning image 4 on page 32...\n",
      "    -> Captioning image 5 on page 32...\n",
      "    -> Captioning image 6 on page 32...\n",
      "    -> Captioning image 1 on page 33...\n",
      "    -> Captioning image 2 on page 33...\n",
      "    -> Captioning image 1 on page 34...\n",
      "    -> Captioning image 2 on page 34...\n",
      "    -> Captioning image 3 on page 34...\n",
      "    -> Captioning image 4 on page 34...\n",
      "    -> Captioning image 5 on page 34...\n",
      "    -> Captioning image 1 on page 35...\n",
      "    -> Captioning image 2 on page 35...\n",
      "    -> Captioning image 3 on page 35...\n",
      "    -> Captioning image 4 on page 35...\n",
      "    -> Captioning image 1 on page 36...\n",
      "    -> Captioning image 2 on page 36...\n",
      "    -> Captioning image 3 on page 36...\n",
      "    -> Captioning image 1 on page 37...\n",
      "    -> Captioning image 2 on page 37...\n",
      "    -> Captioning image 1 on page 38...\n",
      "    -> Captioning image 2 on page 38...\n",
      "    -> Captioning image 3 on page 38...\n",
      "    -> Captioning image 1 on page 39...\n",
      "    -> Captioning image 2 on page 39...\n",
      "    -> Captioning image 1 on page 40...\n",
      "    -> Captioning image 2 on page 40...\n",
      "    -> Captioning image 3 on page 40...\n",
      "    -> Captioning image 1 on page 41...\n",
      "    -> Captioning image 2 on page 41...\n",
      "    -> Captioning image 3 on page 41...\n",
      "    -> Captioning image 4 on page 41...\n",
      "    -> Captioning image 1 on page 42...\n",
      "    -> Captioning image 2 on page 42...\n",
      "    -> Captioning image 1 on page 43...\n",
      "    -> Captioning image 2 on page 43...\n",
      "    -> Captioning image 1 on page 44...\n",
      "    -> Captioning image 2 on page 44...\n",
      "    -> Captioning image 3 on page 44...\n",
      "    -> Captioning image 1 on page 45...\n",
      "    -> Captioning image 2 on page 45...\n",
      "    -> Captioning image 3 on page 45...\n",
      "    -> Captioning image 1 on page 46...\n",
      "    -> Captioning image 2 on page 46...\n",
      "    -> Captioning image 3 on page 46...\n",
      "    -> Captioning image 4 on page 46...\n",
      "    -> Captioning image 1 on page 47...\n",
      "    -> Captioning image 2 on page 47...\n",
      "    -> Captioning image 3 on page 47...\n",
      "    -> Captioning image 4 on page 47...\n",
      "    -> Captioning image 1 on page 48...\n",
      "    -> Captioning image 2 on page 48...\n",
      "    -> Captioning image 3 on page 48...\n",
      "    -> Captioning image 4 on page 48...\n",
      "    -> Captioning image 1 on page 49...\n",
      "    -> Captioning image 2 on page 49...\n",
      "    -> Captioning image 3 on page 49...\n",
      "    -> Captioning image 4 on page 49...\n",
      "    -> Captioning image 1 on page 50...\n",
      "    -> Captioning image 2 on page 50...\n",
      "    -> Captioning image 3 on page 50...\n",
      "    -> Captioning image 4 on page 50...\n",
      "    -> Captioning image 1 on page 51...\n",
      "    -> Captioning image 2 on page 51...\n",
      "    -> Captioning image 3 on page 51...\n",
      "    -> Captioning image 4 on page 51...\n",
      "    -> Captioning image 1 on page 52...\n",
      "    -> Captioning image 2 on page 52...\n",
      "    -> Captioning image 3 on page 52...\n",
      "    -> Captioning image 4 on page 52...\n",
      "    -> Captioning image 1 on page 53...\n",
      "    -> Captioning image 2 on page 53...\n",
      "    -> Captioning image 3 on page 53...\n",
      "    -> Captioning image 4 on page 53...\n",
      "    -> Captioning image 5 on page 53...\n",
      "    -> Captioning image 1 on page 54...\n",
      "    -> Captioning image 2 on page 54...\n",
      "    -> Captioning image 3 on page 54...\n",
      "    -> Captioning image 4 on page 54...\n",
      "    -> Captioning image 1 on page 55...\n",
      "    -> Captioning image 2 on page 55...\n",
      "    -> Captioning image 3 on page 55...\n",
      "    -> Captioning image 4 on page 55...\n",
      "    -> Captioning image 5 on page 55...\n",
      "    -> Captioning image 6 on page 55...\n",
      "    -> Captioning image 1 on page 56...\n",
      "    -> Captioning image 2 on page 56...\n",
      "    -> Captioning image 3 on page 56...\n",
      "    -> Captioning image 1 on page 57...\n",
      "    -> Captioning image 2 on page 57...\n",
      "    -> Captioning image 3 on page 57...\n",
      "    -> Captioning image 4 on page 57...\n",
      "    -> Captioning image 5 on page 57...\n",
      "    -> Captioning image 1 on page 58...\n",
      "    -> Captioning image 2 on page 58...\n",
      "    -> Captioning image 3 on page 58...\n",
      "    -> Captioning image 4 on page 58...\n",
      "    -> Captioning image 5 on page 58...\n",
      "    -> Captioning image 1 on page 59...\n",
      "    -> Captioning image 2 on page 59...\n",
      "    -> Captioning image 3 on page 59...\n",
      "    -> Captioning image 4 on page 59...\n",
      "    -> Captioning image 1 on page 60...\n",
      "    -> Captioning image 2 on page 60...\n",
      "    -> Captioning image 1 on page 61...\n",
      "    -> Captioning image 2 on page 61...\n",
      "    -> Captioning image 3 on page 61...\n",
      "    -> Captioning image 1 on page 62...\n",
      "    -> Captioning image 2 on page 62...\n",
      "    -> Captioning image 3 on page 62...\n",
      "    -> Captioning image 1 on page 63...\n",
      "    -> Captioning image 2 on page 63...\n",
      "    -> Captioning image 3 on page 63...\n",
      "    -> Captioning image 1 on page 64...\n",
      "    -> Captioning image 2 on page 64...\n",
      "    -> Captioning image 3 on page 64...\n",
      "    -> Captioning image 4 on page 64...\n",
      "    -> Captioning image 5 on page 64...\n",
      "    -> Captioning image 6 on page 64...\n",
      "    -> Captioning image 7 on page 64...\n",
      "    -> Captioning image 1 on page 65...\n",
      "    -> Captioning image 2 on page 65...\n",
      "    -> Captioning image 1 on page 66...\n",
      "    -> Captioning image 2 on page 66...\n",
      "    -> Captioning image 3 on page 66...\n",
      "    -> Captioning image 4 on page 66...\n",
      "    -> Captioning image 1 on page 67...\n",
      "    -> Captioning image 2 on page 67...\n",
      "    -> Captioning image 3 on page 67...\n",
      "    -> Captioning image 4 on page 67...\n",
      "    -> Captioning image 1 on page 68...\n",
      "    -> Captioning image 2 on page 68...\n",
      "    -> Captioning image 3 on page 68...\n",
      "    -> Captioning image 1 on page 69...\n",
      "    -> Captioning image 2 on page 69...\n",
      "    -> Captioning image 3 on page 69...\n",
      "    -> Captioning image 1 on page 70...\n",
      "    -> Captioning image 2 on page 70...\n",
      "    -> Captioning image 3 on page 70...\n",
      "    -> Captioning image 1 on page 71...\n",
      "    -> Captioning image 2 on page 71...\n",
      "    -> Captioning image 3 on page 71...\n",
      "    -> Captioning image 1 on page 72...\n",
      "    -> Captioning image 2 on page 72...\n",
      "    -> Captioning image 3 on page 72...\n",
      "    -> Captioning image 1 on page 73...\n",
      "    -> Captioning image 2 on page 73...\n",
      "    -> Captioning image 3 on page 73...\n",
      "    -> Captioning image 1 on page 74...\n",
      "    -> Captioning image 2 on page 74...\n",
      "    -> Captioning image 3 on page 74...\n",
      "    -> Captioning image 4 on page 74...\n",
      "    -> Captioning image 5 on page 74...\n",
      "    -> Captioning image 1 on page 75...\n",
      "    -> Captioning image 2 on page 75...\n",
      "    -> Captioning image 3 on page 75...\n",
      "    -> Captioning image 4 on page 75...\n",
      "    -> Captioning image 1 on page 76...\n",
      "    -> Captioning image 2 on page 76...\n",
      "    -> Captioning image 3 on page 76...\n",
      "    -> Captioning image 4 on page 76...\n",
      "    -> Captioning image 1 on page 77...\n",
      "    -> Captioning image 2 on page 77...\n",
      "    -> Captioning image 3 on page 77...\n",
      "    -> Captioning image 1 on page 78...\n",
      "    -> Captioning image 2 on page 78...\n",
      "    -> Captioning image 3 on page 78...\n",
      "    -> Captioning image 1 on page 79...\n",
      "    -> Captioning image 2 on page 79...\n",
      "    -> Captioning image 3 on page 79...\n",
      "    -> Captioning image 4 on page 79...\n",
      "    -> Captioning image 5 on page 79...\n",
      "    -> Captioning image 1 on page 80...\n",
      "    -> Captioning image 2 on page 80...\n",
      "    -> Captioning image 3 on page 80...\n",
      "    -> Captioning image 4 on page 80...\n",
      "    -> Captioning image 5 on page 80...\n",
      "    -> Captioning image 6 on page 80...\n",
      "    -> Captioning image 1 on page 81...\n",
      "    -> Captioning image 2 on page 81...\n",
      "    -> Captioning image 3 on page 81...\n",
      "    -> Captioning image 4 on page 81...\n",
      "    -> Captioning image 1 on page 82...\n",
      "    -> Captioning image 2 on page 82...\n",
      "    -> Captioning image 1 on page 83...\n",
      "    -> Captioning image 2 on page 83...\n",
      "    -> Captioning image 1 on page 84...\n",
      "    -> Captioning image 2 on page 84...\n",
      "    -> Captioning image 3 on page 84...\n",
      "    -> Captioning image 4 on page 84...\n",
      "    -> Captioning image 5 on page 84...\n",
      "    -> Captioning image 6 on page 84...\n",
      "    -> Captioning image 7 on page 84...\n",
      "    -> Captioning image 1 on page 85...\n",
      "    -> Captioning image 2 on page 85...\n",
      "    -> Captioning image 3 on page 85...\n",
      "    -> Captioning image 4 on page 85...\n",
      "    -> Captioning image 5 on page 85...\n",
      "    -> Captioning image 1 on page 86...\n",
      "    -> Captioning image 2 on page 86...\n",
      "    -> Captioning image 3 on page 86...\n",
      "    -> Captioning image 4 on page 86...\n",
      "    -> Captioning image 1 on page 87...\n",
      "    -> Captioning image 2 on page 87...\n",
      "    -> Captioning image 3 on page 87...\n",
      "    -> Captioning image 1 on page 88...\n",
      "    -> Captioning image 2 on page 88...\n",
      "    -> Captioning image 1 on page 89...\n",
      "    -> Captioning image 2 on page 89...\n",
      "    -> Captioning image 3 on page 89...\n",
      "    -> Captioning image 4 on page 89...\n",
      "    -> Captioning image 5 on page 89...\n",
      "    -> Captioning image 6 on page 89...\n",
      "    -> Captioning image 1 on page 90...\n",
      "    -> Captioning image 2 on page 90...\n",
      "    -> Captioning image 3 on page 90...\n",
      "    -> Captioning image 1 on page 91...\n",
      "    -> Captioning image 2 on page 91...\n",
      "    -> Captioning image 3 on page 91...\n",
      "    -> Captioning image 4 on page 91...\n",
      "    -> Captioning image 5 on page 91...\n",
      "    -> Captioning image 1 on page 92...\n",
      "    -> Captioning image 2 on page 92...\n",
      "    -> Captioning image 3 on page 92...\n",
      "    -> Captioning image 4 on page 92...\n",
      "    -> Captioning image 5 on page 92...\n",
      "    -> Captioning image 1 on page 93...\n",
      "    -> Captioning image 2 on page 93...\n",
      "    -> Captioning image 3 on page 93...\n",
      "\n",
      "Finished parsing. Total documents created: 753\n",
      "Successfully saved all 753 documents to multimodal_documents_cache.pkl.\n",
      "\n",
      "Total documents (text chunks + image captions) available: 753\n"
     ]
    }
   ],
   "source": [
    "# Multi-Modal PDF Parsing and Captioning\n",
    "import os\n",
    "import pickle\n",
    "import io\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import fitz # PyMuPDF\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def extract_and_caption_pdf(filename: str, pdf_content: bytes) -> List[Document]:\n",
    "    \"\"\"Extracts text and images from in-memory PDF content, captions images, and returns LangChain Documents.\"\"\"\n",
    "    print(f\"\\nProcessing {filename}...\", flush=True)\n",
    "    \n",
    "    # Open the PDF from the in-memory byte stream\n",
    "    doc = fitz.open(stream=pdf_content, filetype=\"pdf\")\n",
    "    all_content = []\n",
    "    \n",
    "    # 1. Extract Text Chunks (Unchanged)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text()\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            doc_metadata = {\"source\": filename, \"page\": i + 1, \"chunk_id\": f\"P{i+1}-T{j}\"}\n",
    "            all_content.append(Document(page_content=chunk, metadata=doc_metadata))\n",
    "\n",
    "    # 2. Extract and Caption Images\n",
    "    if 'inspection_survey' in filename.lower():\n",
    "        print(f\"  -> {filename} identified as image-containing. Beginning image extraction...\", flush=True)\n",
    "        \n",
    "        for i, page in enumerate(doc):\n",
    "            image_list = page.get_images(full=True)\n",
    "            for j, img_info in enumerate(image_list):\n",
    "                try:\n",
    "                    xref = img_info[0]\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    \n",
    "                    # Defensive Image Loading and Normalization\n",
    "                    img_stream = io.BytesIO(image_bytes)\n",
    "                    image = Image.open(img_stream)\n",
    "                    \n",
    "                    # Convert to RGB to fix 'Unable to infer channel dimension' errors\n",
    "                    if image.mode != 'RGB':\n",
    "                        image = image.convert('RGB')\n",
    "                    \n",
    "                    # Memory Optimization (Resizing)\n",
    "                    MAX_DIM = 1024\n",
    "                    if max(image.size) > MAX_DIM:\n",
    "                        image.thumbnail((MAX_DIM, MAX_DIM), Image.Resampling.LANCZOS)\n",
    "                        \n",
    "                    # --- Captioning ---\n",
    "                    print(f\"    -> Captioning image {j+1} on page {i+1}...\", flush=True)\n",
    "                    \n",
    "                    conversation = [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"image\", \"image\": image},\n",
    "                                {\"type\": \"text\", \"text\": \"Describe this image, chart, or diagram in detail. Summarize its key findings or data points.\"},\n",
    "                            ],\n",
    "                        },\n",
    "                    ]\n",
    "                    \n",
    "                    # Apply chat template and generate\n",
    "                    inputs = hf_processor.apply_chat_template(\n",
    "                        conversation,\n",
    "                        add_generation_prompt=True,\n",
    "                        tokenize=True,\n",
    "                        return_dict=True,\n",
    "                        return_tensors=\"pt\"\n",
    "                    ).to(HF_DEVICE)\n",
    "                    \n",
    "                    # Use Bfloat16 for input tensors to match the model's dtype\n",
    "                    if hf_vision_model.dtype == torch.bfloat16:\n",
    "                        inputs = {k: v.to(torch.bfloat16) if v.is_floating_point() else v for k, v in inputs.items()}\n",
    "                        \n",
    "                    output = hf_vision_model.generate(**inputs, max_new_tokens=256)\n",
    "                    caption = hf_processor.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "                    # Create document from caption\n",
    "                    caption_doc = f\"IMAGE CAPTION (Source: {filename}, Page {i+1}, Image {j+1}): {caption}\"\n",
    "                    img_metadata = {\"source\": filename, \"page\": i + 1, \"chunk_id\": f\"P{i+1}-I{j}\", \"type\": \"image_caption\"}\n",
    "                    all_content.append(Document(page_content=caption_doc, metadata=img_metadata))\n",
    "                    \n",
    "                    # Aggressive Memory Clearing\n",
    "                    del inputs\n",
    "                    del output\n",
    "                    torch.cuda.empty_cache() \n",
    "                    gc.collect() \n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    Error processing image on page {i+1}, image {j+1}: {e}\", flush=True)\n",
    "                    # Clear memory even on error\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                    continue\n",
    "                    \n",
    "    return all_content\n",
    "\n",
    "# Execution of the Multi-modal Parsing (Caching Logic Added)\n",
    "\n",
    "CACHE_FILE = 'multimodal_documents_cache.pkl'\n",
    "all_documents = []\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    # Load from Cache\n",
    "    print(f\"\\nCache file found: {CACHE_FILE}. Loading documents from cache...\", flush=True)\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'rb') as f:\n",
    "            all_documents = pickle.load(f)\n",
    "        print(\"Documents successfully loaded from cache. Skipping multi-modal parsing.\", flush=True)\n",
    "    except Exception as e:\n",
    "        # Fallback if the cache file is corrupted\n",
    "        print(f\"Error loading cache file: {e}. Attempting to run full parsing.\", flush=True)\n",
    "        os.remove(CACHE_FILE) # Delete bad cache\n",
    "        \n",
    "else:\n",
    "    # Run Expensive Parsing and Save to Cache\n",
    "    print(f\"\\nCache file not found. Running Multi-Modal PDF Parsing and Captioning...\", flush=True)\n",
    "    \n",
    "    # Assuming 'pdf_files' dictionary is populated from your COS retrieval step\n",
    "    for filename, content in pdf_files.items():\n",
    "        all_documents.extend(extract_and_caption_pdf(filename, content))\n",
    "        \n",
    "    print(f\"\\nFinished parsing. Total documents created: {len(all_documents)}\", flush=True)\n",
    "    \n",
    "    # Save the results\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'wb') as f:\n",
    "            pickle.dump(all_documents, f)\n",
    "        print(f\"Successfully saved all {len(all_documents)} documents to {CACHE_FILE}.\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\"WARNING: Could not save cache file {CACHE_FILE}: {e}\", flush=True)\n",
    "\n",
    "\n",
    "print(f\"\\nTotal documents (text chunks + image captions) available: {len(all_documents)}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parsing will:\n",
    "\n",
    "•\tDefine the function and uses `fitz` to accurately pull both text and embedded image bytes from structured documents, a task simple text readers often fail at.\n",
    "\n",
    "•\tPass the extracted images and a descriptive prompt to the locally loaded granite vision model as it is crucial for multi-modality. By converting images into descriptive text captions, we make visual information searchable via the standard text embedding model.This mechanism ensures the agent is not \"blind\" to non-textual context, thus improves the completeness of the knowledge base.\n",
    "\n",
    "•\tImplement caching logic to store the results, preventing the time-consuming and computationally demanding multi-modal captioning process from having to be repeated. Storing the processed knowledge base speeds up development and repeated execution.\n",
    "\n",
    "•\tEnsure the final knowledge base gives the self-reflective agent full context that includes both textual and visual data. This is the main objective of the entire process, giving the later self-reflective retrieval the foundation it needs to be precise and well-founded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. Indexing and retriever setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step completes the preparation of the multi-modal knowledge base by indexing all processed document chunks into an efficient, searchable vector store, which forms the basis for the agent's initial retrieval capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44ff314a-0ac0-48c5-a6ea-23f96a8eb0a0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Vector Store Creation ---\n",
      "Vector Store created successfully with 753 documents.\n",
      "Retriever configured (k=5). Ready for RAG.\n"
     ]
    }
   ],
   "source": [
    "# Indexing and Retriever Setup \n",
    "from langchain_ibm import WatsonxEmbeddings \n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "print(\"\\n Starting Vector Store Creation \", flush=True)\n",
    "\n",
    "try:\n",
    "    # Create the FAISS Vector Store\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=all_documents,\n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    print(f\"Vector Store created successfully with {len(all_documents)} documents.\", flush=True)\n",
    "\n",
    "    # Create the Retriever\n",
    "    # We set 'k=5' to retrieve the top 5 most similar documents for any given query.\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    print(\"Retriever configured (k=5). Ready for RAG.\", flush=True)\n",
    "\n",
    "except Exception as e:\n",
    "    # This captures errors like embedding failures.\n",
    "    print(f\"Vector Store creation failed: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration plays a key role in preparing the retrieval layer for the self-RAG workflow:\n",
    "\n",
    "•\tIt builds a high efficiency vector store using FAISS, which is well known for its speed and scalability when handling dense vector indexes. This ensures that similarity searches run quickly which is critical for maintaining a responsive RAG pipeline.\n",
    "\n",
    "•\tIt transforms the multi modal knowledge base into vector representations, allowing the retriever to match user queries by meaning rather than relying on exact keyword overlap.\n",
    "\n",
    "•\tIt fine tunes context delivery by typically retrieving the top five most relevant documents (k=5), balancing precision and relevance within the model’s context window.\n",
    "\n",
    "•\tIt establishes a single, consistent knowledge source that the self RAG agent can depend on for factual grounding that is an essential element of any trustworthy retrieval augmented system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10. LangGraph state and core self-RAG logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step sets up the main sections of the self-RAG workflow. The agent state tracks the entire process. The LangGraph node functions manage the flexible, self-correcting logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5518cdb9-95eb-4bf0-a12d-0ec488bde113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building and Compiling LangGraph Workflow ---\n",
      "LangGraph workflow compiled successfully (object named 'app').\n"
     ]
    }
   ],
   "source": [
    "# LangGraph state and core self-RAG logic\n",
    "\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph, END\n",
    "import re\n",
    "# Assumed objects: qa_llm, retriever, calculate_score (defined below)\n",
    "\n",
    "\n",
    "# Define the Agent State (Schema)\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Represents the state of the Self-RAG agent.\"\"\"\n",
    "    query: str                       # The original user query\n",
    "    retrieved_docs: List[Document]   # Documents retrieved from the vector store\n",
    "    generation_history: List[str]    # History of generated segments\n",
    "    critique_score: float            # The critique score of the last generated segment\n",
    "    segment_count: int               # Counter for generated segments\n",
    "    finish_generation: bool          # Flag to stop the generation loop\n",
    "\n",
    "\n",
    "# LangGraph Node Functions (SELF-RAG Logic)\n",
    "MAX_SEGMENTS = 10 \n",
    "SCORE_THRESHOLD = 2.5 # Defined here for convenience, but also used in evaluate_critique\n",
    "\n",
    "def calculate_score(isrel_val: str, issup_val: str, isuse_val: int) -> float:\n",
    "    \"\"\"Calculates the combined weighted score for a segment (Soft Constraint).\"\"\"\n",
    "    W_ISSUP = 3.0  \n",
    "    W_ISREL = 1.5  \n",
    "    W_ISUSE = 0.5  \n",
    "\n",
    "    score_rel = 1.0 if isrel_val == \"Relevant\" else 0.0\n",
    "    \n",
    "    if \"Fully Supported\" in issup_val:\n",
    "        score_sup = 1.0\n",
    "    elif \"Partially\" in issup_val:\n",
    "        score_sup = 0.5\n",
    "    else:\n",
    "        score_sup = 0.0\n",
    "\n",
    "    score_use = (isuse_val - 1) / 4.0  \n",
    "    \n",
    "    total_score = (W_ISREL * score_rel) + (W_ISSUP * score_sup) + (W_ISUSE * score_use)\n",
    "    return total_score\n",
    "\n",
    "\n",
    "def initial_decision(state: AgentState) -> AgentState:\n",
    "    \"\"\"Initial decision on whether to retrieve based on the query type.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert self-reflecting LLM. Your task is to determine if external knowledge is required to answer the following query accurately.\n",
    "    - If knowledge is required, output the token: <|Retrieve=Yes|>\n",
    "    - If the query is open-ended or based on common knowledge, output the token: <|Retrieve=No|>\n",
    "\n",
    "    Query: \"{query}\"\n",
    "\n",
    "    Decision Token:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = qa_llm.invoke(prompt)\n",
    "    \n",
    "    if \"<|Retrieve=Yes|>\" in response:\n",
    "        print(\"Decision: Retrieval required.\", flush=True) \n",
    "        return {\"query\": query, \"retrieved_docs\": [], \"critique_score\": 0.0, \"segment_count\": 0, \"finish_generation\": False}\n",
    "    else:\n",
    "        print(\"Decision: No retrieval required for initial generation.\", flush=True) \n",
    "        return {\"query\": query, \"retrieved_docs\": [Document(page_content=\"No documents retrieved.\")], \"critique_score\": 0.0, \"segment_count\": 0, \"finish_generation\": False}\n",
    "\n",
    "\n",
    "def retrieve_docs(state: AgentState) -> AgentState:\n",
    "    \"\"\"Retrieves documents based on the current query or the last generated segment.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    if state.get(\"generation_history\"):\n",
    "        search_query = state[\"generation_history\"][-1]\n",
    "    else:\n",
    "        search_query = query\n",
    "        \n",
    "    print(f\"Retrieving documents for: '{search_query[:50]}...'\", flush=True) \n",
    "    docs = retriever.invoke(search_query)\n",
    "    \n",
    "    return {\"retrieved_docs\": docs}\n",
    "\n",
    "\n",
    "def generate_segment(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generates the next answer segment and self-reflects using critique tokens.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    history = state.get(\"generation_history\", [])\n",
    "    \n",
    "    docs_context = \"\\n---\\n\".join([f\"Source ({d.metadata.get('chunk_id')}): {d.page_content}\" for d in state[\"retrieved_docs\"]])\n",
    "    history_context = \"\\n\".join(history)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a SELF-RAG agent using the IBM Granite model. Your goal is to generate one accurate, concise segment of an answer.\n",
    "    \n",
    "    INSTRUCTION: Generate a comprehensive, multi-segment answer to the user's query.\n",
    "    1. CONTEXT: Use the provided document segments (which include text and image captions) to answer the question accurately.\n",
    "    2. SEGMENTATION: Only use the <|END|> token when the answer is fully comprehensive and detailed, and you have no more relevant information to add.\n",
    "    3. REFLECTION: After generating the segment, immediately append these key-value reflection tokens:\n",
    "        - ISREL: <|ISREL=Relevant|> or <|ISREL=Irrelevant|>\n",
    "        - ISSUP: <|ISSUP=Fully Supported|> or <|ISSUP=Partially Supported|> or <|ISSUP=No Support|>\n",
    "        - ISUSE: <|ISUSE=N|> (where N is the overall quality/utility score from 1 to 5, 5 is best).\n",
    "        \n",
    "    CURRENT QUERY: \"{query}\"\n",
    "    \n",
    "    HISTORY SO FAR: \"{history_context}\"\n",
    "    \n",
    "    RETRIEVED CONTEXT (Multi-Modal: text chunks and image captions):\n",
    "    {docs_context}\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Generate the NEXT SEGMENT and REFLECTION TOKENS. End the entire generation with <|END|> if the answer is complete.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Generating Segment {state['segment_count'] + 1}...\", flush=True) \n",
    "    full_response = qa_llm.invoke(prompt)\n",
    "\n",
    "    CRITIQUE_TOKENS = [\"<|ISREL=\", \"<|ISSUP=\", \"<|ISUSE=\", \"|>\"] \n",
    "\n",
    "    isrel = re.search(r\"<\\|ISREL=(.+?)\\|>\", full_response)\n",
    "    issup = re.search(r\"<\\|ISSUP=(.+?)\\|>\", full_response)\n",
    "    isuse = re.search(r\"<\\|ISUSE=(\\d+)\\|>\", full_response)\n",
    "    \n",
    "    isrel_val = isrel.group(1).strip() if isrel else \"Irrelevant\"\n",
    "    issup_val = issup.group(1).strip() if issup else \"No Support\"\n",
    "    isuse_val = int(isuse.group(1).strip()) if isuse and isuse.group(1).isdigit() else 1\n",
    "\n",
    "    segment = full_response\n",
    "    for token in CRITIQUE_TOKENS + [\"<|Retrieve=Yes|>\", \"<|Retrieve=No|>\", \"<|END|>\"]:\n",
    "        segment = segment.replace(token, \"\").strip()\n",
    "    \n",
    "    new_history = history + [segment]\n",
    "    \n",
    "    print(f\"  -> ISREL: {isrel_val}, ISSUP: {issup_val}, ISUSE: {isuse_val}\", flush=True) \n",
    "    \n",
    "    return {\n",
    "        \"generation_history\": new_history,\n",
    "        \"segment_count\": state[\"segment_count\"] + 1,\n",
    "        \"finish_generation\": \"<|END|>\" in full_response,\n",
    "        \"critique_score\": calculate_score(isrel_val, issup_val, isuse_val), \n",
    "        \"retrieved_docs\": state[\"retrieved_docs\"] \n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_critique(state: AgentState) -> str:\n",
    "    \"\"\"Conditional edge function to determine the next step based on critique score.\"\"\"\n",
    "    score = state[\"critique_score\"]\n",
    "    segment_count = state[\"segment_count\"]\n",
    "    is_finished = state[\"finish_generation\"]\n",
    "    \n",
    "    if is_finished or segment_count >= MAX_SEGMENTS:\n",
    "        return \"end\"\n",
    "    \n",
    "    if score < SCORE_THRESHOLD:\n",
    "        print(f\"Critique: Low score ({score:.2f}) observed. FORCING RE-RETRIEVAL for next segment.\", flush=True) \n",
    "        return \"retrieve\"  \n",
    "    \n",
    "    print(f\"Critique: High score ({score:.2f}) observed. Continuing generation.\", flush=True)\n",
    "    return \"continue\"\n",
    "\n",
    "\n",
    "def finalize_answer(state: AgentState) -> AgentState:\n",
    "    \"\"\"Compiles the final answer.\"\"\"\n",
    "    final_answer = \"\\n\".join(state[\"generation_history\"])\n",
    "    print(\"\\n--- FINAL ANSWER ---\", flush=True) \n",
    "    print(final_answer, flush=True)\n",
    "    return state\n",
    "\n",
    "\n",
    "# Build and Compile the LangGraph Workflow\n",
    "\n",
    "print(\"\\n Building and Compiling LangGraph Workflow \", flush=True)\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes (Function Calls)\n",
    "workflow.add_node(\"initial_decision\", initial_decision)\n",
    "workflow.add_node(\"retrieve_docs\", retrieve_docs)\n",
    "workflow.add_node(\"generate_segment\", generate_segment)\n",
    "workflow.add_node(\"finalize_answer\", finalize_answer)\n",
    "\n",
    "\n",
    "# Define Edges (Flow Control)\n",
    "workflow.set_entry_point(\"initial_decision\")\n",
    "\n",
    "# Edge 1: Decide between retrieval or initial generation\n",
    "workflow.add_conditional_edges(\n",
    "    \"initial_decision\", \n",
    "    lambda state: \"retrieve\" if not state[\"retrieved_docs\"] else \"generate\",\n",
    "    {\n",
    "        \"retrieve\": \"retrieve_docs\",\n",
    "        \"generate\": \"generate_segment\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Edge 2: After retrieval, always generate a segment\n",
    "workflow.add_edge(\"retrieve_docs\", \"generate_segment\")\n",
    "\n",
    "\n",
    "# Edge 3: The core loop - Evaluate the critique score to determine the next action\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_segment\",\n",
    "    evaluate_critique, \n",
    "    {\n",
    "        \"retrieve\": \"retrieve_docs\",\n",
    "        \"continue\": \"generate_segment\",\n",
    "        \"end\": \"finalize_answer\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Edge 4: End the workflow\n",
    "workflow.add_edge(\"finalize_answer\", END)\n",
    "\n",
    "\n",
    "# Compile the Graph\n",
    "app = workflow.compile()\n",
    "print(\"LangGraph workflow compiled successfully (object named 'app').\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code serves several purposes:\n",
    "\n",
    "•\tThe agent keeps a core memory that stores its evolving response, the evidence it has retrieved, and internal feedback. This memory helps the agent's logic to dynamically improve its reasoning by storing context across various steps.\n",
    "\n",
    "•\t The agent first determines whether adequate factual grounding is present before producing any segments. To ensure that the generated response is accurate and pertinent, the agent intelligently seeks for stronger, more supportive information if the existing context is deemed incomplete.\n",
    "\n",
    "•\tAlongside each generated segment, the model issues internal reflection tokens that immediately quantify the output's relevance, factual support, and overall quality. These critical signals are then combined into a single critique score, giving the agent an objective, measurable way to judge its own performance.\n",
    "\n",
    "•\tDetermined by the critique score, the agent then decides whether to rework, expand upon, or finalize its answer. This iterative process makes the system inherently resilient, forcing it to improve incorrect generations and maintain factual precision over multiple reasoning rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11. LangGraph state and core self-RAG logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire self-RAG workflow begins with this last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4054d5bd-1099-4b4e-8abb-1ac75c9f989b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING LANGGRAPH EXECUTION ---\n",
      "Query: What is the primary purpose of the ICH E6(R3) Guideline and what are the key findings from the EFPIA 2024 inspection survey regarding remote inspections?\n",
      "\n",
      "Decision: Retrieval required.\n",
      "{'initial_decision': {'query': 'What is the primary purpose of the ICH E6(R3) Guideline and what are the key findings from the EFPIA 2024 inspection survey regarding remote inspections?', 'retrieved_docs': [], 'critique_score': 0.0, 'segment_count': 0, 'finish_generation': False}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "Retrieving documents for: 'What is the primary purpose of the ICH E6(R3) Guid...'\n",
      "{'retrieve_docs': {'retrieved_docs': [Document(id='399b5b94-41dd-460a-84ad-69d9da64aedb', metadata={'source': 'inspection_survey.pdf', 'page': 30, 'chunk_id': 'P30-T0'}, page_content='30\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nA strong basis of an inspection using physical \\npresence by a strengthened domestic inspectorate\\nCollaboration, Reliance, Recognition\\nSCIENCE AND RISK-BASED INSPECTION APPROACH\\nReal time \\nremote presence \\nDocument\\nreview\\nMutual Recognition \\nAgreement (MRA)\\nUnilateral \\nreliance*\\n*based on information from other stringent regulatory authorities'), Document(id='f487f42e-80e6-4514-b511-5b5aeeb2efce', metadata={'source': 'inspection_survey.pdf', 'page': 21, 'chunk_id': 'P21-T0'}, page_content='21\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\n• Guidance on good practices for desk assessment… for medical products regulatory decisions, WHO, \\nTRS 1010 (2018), Annex 9.\\n• Good reliance practices in the regulation of medical products: high level principles and \\nconsiderations, WHO, TRS 1033, Annex 10, 2022, 237-267.\\n• International regulators recommend use of remote inspections as complementary tool beyond \\npandemic, EMA-News, 13. Dec 2022.\\n• Guidance related to GMP/GDP and PMF: distant assessments. EMA/335293/2020, 15. Oct. 2020\\n• Remote Interactive Evaluations of Drug…, FDA , Guidance for Industry, FDA-2020-D-1136, April 22\\n• Conducting Remote Regulatory Assessments, Q&A, FDA draft guidance for industry, July 22\\n• Joint Audit Programme for EEA GMP inspectorates - JAP Procedure (Rev.3)\\n• Report on the review of regulatory flexibilities/agilities as implemented by National Regulatory'), Document(id='f0861537-f5b9-4d90-b13e-bf4041c79bc6', metadata={'source': 'inspection_survey.pdf', 'page': 18, 'chunk_id': 'P18-T0'}, page_content='18\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEFPIA member companies welcome the expansion of the pilot and \\nflexibility adopting the inspection approach\\nThere is opportunity to put all in common practice\\nMinimise increased efforts by using existing procedures e.g.,\\nLocal inspectorate as lead and coordinating inspector\\nUse other time zones for document inspection; use core inspection time for \\nclarifications and interactions\\nOne inspection report with one set of agreed observations; co-\\ninspectors/observers to reference as needed\\nNote: Why companies did not apply in 2024 pilot - responses received\\nUncertainty about the return on investment\\nBusiness priorities / resource allocation / management decisions\\nLimited scope in the first round\\nA reflections on the positive outcome of the ICMRA \\nCollaborative Hybrid Inspection Pilot (CHIP)\\nRELIANCE APPROACH - ANSWERS TO QUESTIONS'), Document(id='321a9682-f1ac-4db4-97a0-2ad2b87891e4', metadata={'source': 'inspection_survey.pdf', 'page': 91, 'chunk_id': 'P91-T0'}, page_content='91\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEU/EEA: Trend of less remote inspections year by year after the pandemic\\nUS: No trend but slightly decreasing\\nRemote (evaluations) and document inspections\\nINSPECTION ACTIVITY – EU/EEA AND US'), Document(id='12290a0d-111f-4373-bec0-5eac7eef3c06', metadata={'source': 'inspection_survey.pdf', 'page': 58, 'chunk_id': 'P58-T0'}, page_content='58\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nFor most inspectorates domestic inspections have more follow up action \\nthan foreign inspections – but not e.g., US-FDA\\nThe order of countries is different on follow up actions reported to be \\naddressed in domestic versus foreign sites – different behaviours?\\nRate of inspections with follow-up actions\\nINSPECTIONS AT MANUFACTURING SITES\\n\\uf0a8Green: EU Member State')]}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "Generating Segment 1...\n",
      "  -> ISREL: Relevant, ISSUP: Fully Supported, ISUSE: 5\n",
      "{'generate_segment': {'generation_history': ['SEGMENT: The ICH E6(R3) Guideline primarily focuses on good clinical practice for design and conduct of clinical trials on medicinal products. It aims to harmonize ethical and scientific quality standards for all aspects of clinical trial conduct. Regarding remote inspections, the EFPIA 2024 inspection survey reveals that while there is a trend of fewer remote inspections in the EU/EEA post-pandemic, the US shows no clear trend, with a slight decrease. The survey also highlights the potential for minimizing increased efforts through existing procedures such as utilizing local inspectorates as leads, leveraging different time zones for document inspection, and ensuring one inspection report with agreed observations. However, uncertainty about return on investment and business priorities were cited as reasons for not applying in the 2024 pilot.\\n\\nISREL: Relevant\\nISSUP: Fully Supported\\nISUSE: 5\\n\\n<|END'], 'segment_count': 1, 'finish_generation': True, 'critique_score': 5.0, 'retrieved_docs': [Document(id='399b5b94-41dd-460a-84ad-69d9da64aedb', metadata={'source': 'inspection_survey.pdf', 'page': 30, 'chunk_id': 'P30-T0'}, page_content='30\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nA strong basis of an inspection using physical \\npresence by a strengthened domestic inspectorate\\nCollaboration, Reliance, Recognition\\nSCIENCE AND RISK-BASED INSPECTION APPROACH\\nReal time \\nremote presence \\nDocument\\nreview\\nMutual Recognition \\nAgreement (MRA)\\nUnilateral \\nreliance*\\n*based on information from other stringent regulatory authorities'), Document(id='f487f42e-80e6-4514-b511-5b5aeeb2efce', metadata={'source': 'inspection_survey.pdf', 'page': 21, 'chunk_id': 'P21-T0'}, page_content='21\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\n• Guidance on good practices for desk assessment… for medical products regulatory decisions, WHO, \\nTRS 1010 (2018), Annex 9.\\n• Good reliance practices in the regulation of medical products: high level principles and \\nconsiderations, WHO, TRS 1033, Annex 10, 2022, 237-267.\\n• International regulators recommend use of remote inspections as complementary tool beyond \\npandemic, EMA-News, 13. Dec 2022.\\n• Guidance related to GMP/GDP and PMF: distant assessments. EMA/335293/2020, 15. Oct. 2020\\n• Remote Interactive Evaluations of Drug…, FDA , Guidance for Industry, FDA-2020-D-1136, April 22\\n• Conducting Remote Regulatory Assessments, Q&A, FDA draft guidance for industry, July 22\\n• Joint Audit Programme for EEA GMP inspectorates - JAP Procedure (Rev.3)\\n• Report on the review of regulatory flexibilities/agilities as implemented by National Regulatory'), Document(id='f0861537-f5b9-4d90-b13e-bf4041c79bc6', metadata={'source': 'inspection_survey.pdf', 'page': 18, 'chunk_id': 'P18-T0'}, page_content='18\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEFPIA member companies welcome the expansion of the pilot and \\nflexibility adopting the inspection approach\\nThere is opportunity to put all in common practice\\nMinimise increased efforts by using existing procedures e.g.,\\nLocal inspectorate as lead and coordinating inspector\\nUse other time zones for document inspection; use core inspection time for \\nclarifications and interactions\\nOne inspection report with one set of agreed observations; co-\\ninspectors/observers to reference as needed\\nNote: Why companies did not apply in 2024 pilot - responses received\\nUncertainty about the return on investment\\nBusiness priorities / resource allocation / management decisions\\nLimited scope in the first round\\nA reflections on the positive outcome of the ICMRA \\nCollaborative Hybrid Inspection Pilot (CHIP)\\nRELIANCE APPROACH - ANSWERS TO QUESTIONS'), Document(id='321a9682-f1ac-4db4-97a0-2ad2b87891e4', metadata={'source': 'inspection_survey.pdf', 'page': 91, 'chunk_id': 'P91-T0'}, page_content='91\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEU/EEA: Trend of less remote inspections year by year after the pandemic\\nUS: No trend but slightly decreasing\\nRemote (evaluations) and document inspections\\nINSPECTION ACTIVITY – EU/EEA AND US'), Document(id='12290a0d-111f-4373-bec0-5eac7eef3c06', metadata={'source': 'inspection_survey.pdf', 'page': 58, 'chunk_id': 'P58-T0'}, page_content='58\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nFor most inspectorates domestic inspections have more follow up action \\nthan foreign inspections – but not e.g., US-FDA\\nThe order of countries is different on follow up actions reported to be \\naddressed in domestic versus foreign sites – different behaviours?\\nRate of inspections with follow-up actions\\nINSPECTIONS AT MANUFACTURING SITES\\n\\uf0a8Green: EU Member State')]}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "SEGMENT: The ICH E6(R3) Guideline primarily focuses on good clinical practice for design and conduct of clinical trials on medicinal products. It aims to harmonize ethical and scientific quality standards for all aspects of clinical trial conduct. Regarding remote inspections, the EFPIA 2024 inspection survey reveals that while there is a trend of fewer remote inspections in the EU/EEA post-pandemic, the US shows no clear trend, with a slight decrease. The survey also highlights the potential for minimizing increased efforts through existing procedures such as utilizing local inspectorates as leads, leveraging different time zones for document inspection, and ensuring one inspection report with agreed observations. However, uncertainty about return on investment and business priorities were cited as reasons for not applying in the 2024 pilot.\n",
      "\n",
      "ISREL: Relevant\n",
      "ISSUP: Fully Supported\n",
      "ISUSE: 5\n",
      "\n",
      "<|END\n",
      "{'finalize_answer': {'query': 'What is the primary purpose of the ICH E6(R3) Guideline and what are the key findings from the EFPIA 2024 inspection survey regarding remote inspections?', 'retrieved_docs': [Document(id='399b5b94-41dd-460a-84ad-69d9da64aedb', metadata={'source': 'inspection_survey.pdf', 'page': 30, 'chunk_id': 'P30-T0'}, page_content='30\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nA strong basis of an inspection using physical \\npresence by a strengthened domestic inspectorate\\nCollaboration, Reliance, Recognition\\nSCIENCE AND RISK-BASED INSPECTION APPROACH\\nReal time \\nremote presence \\nDocument\\nreview\\nMutual Recognition \\nAgreement (MRA)\\nUnilateral \\nreliance*\\n*based on information from other stringent regulatory authorities'), Document(id='f487f42e-80e6-4514-b511-5b5aeeb2efce', metadata={'source': 'inspection_survey.pdf', 'page': 21, 'chunk_id': 'P21-T0'}, page_content='21\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\n• Guidance on good practices for desk assessment… for medical products regulatory decisions, WHO, \\nTRS 1010 (2018), Annex 9.\\n• Good reliance practices in the regulation of medical products: high level principles and \\nconsiderations, WHO, TRS 1033, Annex 10, 2022, 237-267.\\n• International regulators recommend use of remote inspections as complementary tool beyond \\npandemic, EMA-News, 13. Dec 2022.\\n• Guidance related to GMP/GDP and PMF: distant assessments. EMA/335293/2020, 15. Oct. 2020\\n• Remote Interactive Evaluations of Drug…, FDA , Guidance for Industry, FDA-2020-D-1136, April 22\\n• Conducting Remote Regulatory Assessments, Q&A, FDA draft guidance for industry, July 22\\n• Joint Audit Programme for EEA GMP inspectorates - JAP Procedure (Rev.3)\\n• Report on the review of regulatory flexibilities/agilities as implemented by National Regulatory'), Document(id='f0861537-f5b9-4d90-b13e-bf4041c79bc6', metadata={'source': 'inspection_survey.pdf', 'page': 18, 'chunk_id': 'P18-T0'}, page_content='18\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEFPIA member companies welcome the expansion of the pilot and \\nflexibility adopting the inspection approach\\nThere is opportunity to put all in common practice\\nMinimise increased efforts by using existing procedures e.g.,\\nLocal inspectorate as lead and coordinating inspector\\nUse other time zones for document inspection; use core inspection time for \\nclarifications and interactions\\nOne inspection report with one set of agreed observations; co-\\ninspectors/observers to reference as needed\\nNote: Why companies did not apply in 2024 pilot - responses received\\nUncertainty about the return on investment\\nBusiness priorities / resource allocation / management decisions\\nLimited scope in the first round\\nA reflections on the positive outcome of the ICMRA \\nCollaborative Hybrid Inspection Pilot (CHIP)\\nRELIANCE APPROACH - ANSWERS TO QUESTIONS'), Document(id='321a9682-f1ac-4db4-97a0-2ad2b87891e4', metadata={'source': 'inspection_survey.pdf', 'page': 91, 'chunk_id': 'P91-T0'}, page_content='91\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEU/EEA: Trend of less remote inspections year by year after the pandemic\\nUS: No trend but slightly decreasing\\nRemote (evaluations) and document inspections\\nINSPECTION ACTIVITY – EU/EEA AND US'), Document(id='12290a0d-111f-4373-bec0-5eac7eef3c06', metadata={'source': 'inspection_survey.pdf', 'page': 58, 'chunk_id': 'P58-T0'}, page_content='58\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nFor most inspectorates domestic inspections have more follow up action \\nthan foreign inspections – but not e.g., US-FDA\\nThe order of countries is different on follow up actions reported to be \\naddressed in domestic versus foreign sites – different behaviours?\\nRate of inspections with follow-up actions\\nINSPECTIONS AT MANUFACTURING SITES\\n\\uf0a8Green: EU Member State')], 'generation_history': ['SEGMENT: The ICH E6(R3) Guideline primarily focuses on good clinical practice for design and conduct of clinical trials on medicinal products. It aims to harmonize ethical and scientific quality standards for all aspects of clinical trial conduct. Regarding remote inspections, the EFPIA 2024 inspection survey reveals that while there is a trend of fewer remote inspections in the EU/EEA post-pandemic, the US shows no clear trend, with a slight decrease. The survey also highlights the potential for minimizing increased efforts through existing procedures such as utilizing local inspectorates as leads, leveraging different time zones for document inspection, and ensuring one inspection report with agreed observations. However, uncertainty about return on investment and business priorities were cited as reasons for not applying in the 2024 pilot.\\n\\nISREL: Relevant\\nISSUP: Fully Supported\\nISUSE: 5\\n\\n<|END'], 'critique_score': 5.0, 'segment_count': 1, 'finish_generation': True}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "--- LANGGRAPH EXECUTION COMPLETE ---\n"
     ]
    }
   ],
   "source": [
    "# Execute the LangGraph Workflow\n",
    "\n",
    "# 1. Define the Query\n",
    "# This query is designed to require information from both documents.\n",
    "user_query = \"What is the primary purpose of the ICH E6(R3) Guideline and what are the key findings from the EFPIA 2024 inspection survey regarding remote inspections?\"\n",
    "\n",
    "# 2. Define the Initial Input State\n",
    "# The generation_history must start empty.\n",
    "inputs = {\n",
    "    \"query\": user_query, \n",
    "    \"generation_history\": []\n",
    "}\n",
    "\n",
    "print(f\"\\n--- STARTING LANGGRAPH EXECUTION ---\", flush=True)\n",
    "print(f\"Query: {user_query}\\n\", flush=True)\n",
    "\n",
    "# 3. Stream the Execution\n",
    "# This loop runs the graph and prints the state update after each node completes.\n",
    "for step in app.stream(inputs):\n",
    "    # Print the name of the node that just executed and its resulting state\n",
    "    print(step, flush=True)\n",
    "    print(\"\\n--- NODE TRANSITION ---\", flush=True) \n",
    "\n",
    "print(f\"--- LANGGRAPH EXECUTION COMPLETE ---\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1beae79c-4fea-47cb-8de0-319f447b7820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RE-RUNNING EXECUTION FOR FINAL EXTRACTION ---\n",
      "Decision: Retrieval required.\n",
      "Retrieving documents for: 'What is the primary purpose of the ICH E6(R3) Guid...'\n",
      "Generating Segment 1...\n",
      "  -> ISREL: Relevant, ISSUP: Fully Supported, ISUSE: 5\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "SEGMENT: The ICH E6(R3) Guideline primarily focuses on good clinical practice for design and conduct of clinical trials on medicinal products. It aims to harmonize these practices across different regions to ensure the protection of human subjects involved in clinical trials and the quality and integrity of the data generated. Regarding remote inspections, the EFPIA 2024 inspection survey reveals that while there is a trend of fewer remote inspections in the EU/EEA post-pandemic, the US shows no clear trend, with a slight decrease. The survey also highlights the potential for minimizing increased efforts through strategies like utilizing local inspectorates as leads, leveraging different time zones for document reviews, and producing one inspection report with agreed observations. However, uncertainty about return on investment and business priorities were cited as reasons for not applying in the 2024 pilot.\n",
      "\n",
      "ISREL: Relevant\n",
      "ISSUP: Fully Supported\n",
      "ISUSE: 5\n",
      "\n",
      "<|END\n",
      "\n",
      "==============================================\n",
      "✅ RAG PIPELINE COMPLETE\n",
      "==============================================\n",
      "USER QUERY:\n",
      "What is the primary purpose of the ICH E6(R3) Guideline and what are the key findings from the EFPIA 2024 inspection survey regarding remote inspections?\n",
      "\n",
      "FINAL GENERATED ANSWER (1 segments):\n",
      "----------------------------------------------\n",
      "SEGMENT: The ICH E6(R3) Guideline primarily focuses on good clinical practice for design and conduct of clinical trials on medicinal products. It aims to harmonize these practices across different regions to ensure the protection of human subjects involved in clinical trials and the quality and integrity of the data generated. Regarding remote inspections, the EFPIA 2024 inspection survey reveals that while there is a trend of fewer remote inspections in the EU/EEA post-pandemic, the US shows no clear trend, with a slight decrease. The survey also highlights the potential for minimizing increased efforts through strategies like utilizing local inspectorates as leads, leveraging different time zones for document reviews, and producing one inspection report with agreed observations. However, uncertainty about return on investment and business priorities were cited as reasons for not applying in the 2024 pilot.\n",
      "\n",
      "ISREL: Relevant\n",
      "ISSUP: Fully Supported\n",
      "ISUSE: 5\n",
      "\n",
      "<|END\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Final Answer Extraction and Review\n",
    "\n",
    "\n",
    "final_state = None\n",
    "# The query and inputs are reused from Step 10\n",
    "user_query = \"What is the primary purpose of the ICH E6(R3) Guideline and what are the key findings from the EFPIA 2024 inspection survey regarding remote inspections?\"\n",
    "inputs = {\"query\": user_query, \"generation_history\": []}\n",
    "\n",
    "\n",
    "print(\"\\n--- RE-RUNNING EXECUTION FOR FINAL EXTRACTION ---\", flush=True)\n",
    "\n",
    "for step in app.stream(inputs):\n",
    "    for key, value in step.items():\n",
    "        # The key tells us which node just ran (e.g., 'finalize_answer')\n",
    "        # The value is the state output of that node\n",
    "        if key == \"finalize_answer\":\n",
    "            final_state = value \n",
    "        elif key == END:\n",
    "            # If the END node is hit, the graph is finished\n",
    "            final_state = value \n",
    "\n",
    "# 2. Extract and Format the Final Answer\n",
    "if final_state and \"generation_history\" in final_state:\n",
    "    # Join all generated segments into one cohesive answer\n",
    "    final_answer = \"\\n\".join(final_state[\"generation_history\"]).strip()\n",
    "\n",
    "    print(\"\\n==============================================\", flush=True)\n",
    "    print(\" RAG PIPELINE COMPLETE\", flush=True)\n",
    "    print(\"==============================================\", flush=True)\n",
    "    print(f\"USER QUERY:\\n{user_query}\\n\", flush=True)\n",
    "    print(f\"FINAL GENERATED ANSWER ({final_state['segment_count']} segments):\", flush=True)\n",
    "    print(\"----------------------------------------------\", flush=True)\n",
    "    print(final_answer, flush=True)\n",
    "    print(\"----------------------------------------------\", flush=True)\n",
    "else:\n",
    "    print(\"\\n EXECUTION FAILED or final state was not captured.\", flush=True)\n",
    "    print(f\"Last recorded state: {final_state}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the agent either hits the maximum number of segments or completes its multi-segment answer, it produces the final output to the user question. The `.stream()` method is then used to run the compiled graph, represented by the app object.\n",
    "\n",
    "The initial state, which contains the detailed `user_query`, is passed in through the inputs dictionary.\n",
    "\n",
    "As the graph streams, each loop processes one node at a time based on the system’s internal logic. Every node’s output is printed as it runs, letting us watch the agent refine its reasoning in real time and build its multi-part response ultimately ending with a well-supported final answer. The final step reruns the full self-RAG workflow to create a refined answer. It executes the LangGraph and watches the streaming state updates until the `finalize_answer` or `END` node shows up. It pulls the generated segments and joins them into a grounded final answer whenever the final state is reached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ead13a68-b519-49e9-8108-0f21c6df735a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rerunning stream to answer the new query ---\n",
      "Decision: Retrieval required.\n",
      "{'initial_decision': {'query': 'What does the ICH ER6 guideline say about Quality Assurance and Quality Control?', 'retrieved_docs': [], 'critique_score': 0.0, 'segment_count': 0, 'finish_generation': False}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "Retrieving documents for: 'What does the ICH ER6 guideline say about Quality ...'\n",
      "{'retrieve_docs': {'retrieved_docs': [Document(id='7908cddc-7be4-46e8-b8dd-1109af8da414', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 84, 'chunk_id': 'P84-T0'}, page_content='ICH E6(R3) Guideline \\n \\n77 \\n \\nQuality Assurance (QA) \\n \\nAll those planned and systematic actions that are established to ensure that the trial is performed \\nand the data are generated, documented (recorded) and reported in compliance with GCP and \\nthe applicable regulatory requirement(s). \\n \\nQuality Control (QC) \\n \\nThe operational techniques and activities undertaken to verify that the requirements for quality \\nof the trial-related activities have been fulfilled. \\n \\nRandomisation \\n \\nThe process of deliberately including an element of chance when assigning participants to \\ngroups that receive different treatments in order to reduce bias. \\n \\nReference Safety Information (RSI) \\n \\nContains a cumulative list of ADRs that are expected for the investigational product being \\nadministered to participants in a clinical trial. The RSI is included in the Investigator’s \\nBrochure or alternative documents according to applicable regulatory requirements. Refer to'), Document(id='33d0ab06-cc53-4d46-80bb-42bcf7069aed', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 36, 'chunk_id': 'P36-T0'}, page_content='ICH E6(R3) Guideline \\n \\n29 \\n \\n3.10.1.5 Risk Review  \\n \\nThe sponsor should periodically review risk control measures to ascertain whether the \\nimplemented quality management activities remain effective and relevant, taking into \\naccount emerging knowledge and experience. Additional risk control measures may \\nbe implemented as needed. \\n \\n3.10.1.6 Risk Reporting \\n \\nThe sponsor should summarise and report important quality issues (including \\ninstances in which acceptable ranges are exceeded, as detailed in section 3.10.1.3) and \\nthe remedial actions taken and document them in the clinical trial report (see ICH E3).  \\n \\n3.11 \\nQuality Assurance and Quality Control \\n \\nThe sponsor is responsible for establishing, implementing and maintaining \\nappropriate quality assurance and quality control processes and documented \\nprocedures to ensure that trials are conducted and data are generated, recorded and \\nreported in compliance with the protocol, GCP and the applicable regulatory \\nrequirement(s).'), Document(id='8311fdb3-701b-4698-a31d-b1e26efdee8d', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 69, 'chunk_id': 'P69-T0'}, page_content='ICH E6(R3) Guideline \\n \\n62 \\n \\nB.12 \\nQuality Control and Quality Assurance  \\n \\nB.12.1 Description of identified critical to quality factors, associated risks and risk mitigation \\nstrategies in the trial unless documented elsewhere. \\n \\nB.12.2 Summary of the monitoring approaches that are part of the quality control process for \\nthe clinical trial. \\n \\nB.12.3 Description of the process for the handling of noncompliance with the protocol or \\nGCP. \\n \\nB.13 \\nEthics  \\n \\nDescription of ethical considerations relating to the trial.  \\n \\nB.14 \\nData Handling and Record Keeping  \\n \\nB.14.1 Specification of data to be collected and the method of its collection. Where necessary, \\nadditional details should be contained in a clinical trial-related document.  \\n \\nB.14.2 The identification of data to be recorded directly into the data acquisition tools (i.e., \\nno prior written or electronic record of data) and considered to be the source record.'), Document(id='8d26d7ee-6b6a-4d98-9fd4-f0cd145d7f51', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 3, 'chunk_id': 'P3-T0'}, page_content='ICH E6(R3) Guideline \\n \\ni \\n \\nICH HARMONISED GUIDELINE \\nGUIDELINE FOR GOOD CLINICAL PRACTICE \\nE6(R3) \\nICH Consensus Guideline \\nTABLE OF CONTENTS \\nI. \\nINTRODUCTION........................................................................................................ 1 \\nGuideline Scope ......................................................................................................................... 1 \\nGuideline Structure .................................................................................................................... 1 \\nII. \\nPRINCIPLES OF ICH GCP ....................................................................................... 2 \\nIII. \\nANNEX 1 ...................................................................................................................... 7 \\n1. \\nINSTITUTIONAL REVIEW BOARD/INDEPENDENT ETHICS \\nCOMMITTEE (IRB/IEC) ........................................................................................... 7 \\n1.1'), Document(id='7a470ca1-74f8-4dec-bca6-2d770a96b517', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 1, 'chunk_id': 'P1-T0'}, page_content='INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL \\nREQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE \\n \\n \\n \\nICH HARMONISED GUIDELINE \\nGUIDELINE FOR GOOD CLINICAL PRACTICE \\nE6(R3) \\n \\n \\nFinal version  \\nAdopted on 06 January 2025 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis Guideline has been developed by the appropriate ICH Expert Working Group and has been \\nsubject to consultation by the regulatory parties, in accordance with the ICH Process. At Step 4 \\nof the Process the final draft is recommended for adoption to the regulatory bodies of ICH regions.')]}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "Generating Segment 1...\n",
      "  -> ISREL: Relevant, ISSUP: Fully Supported, ISUSE: 5\n",
      "{'generate_segment': {'generation_history': ['\"\"\"\\n\\n\\n## Segment 1:\\n\\nThe ICH E6(R3) guideline outlines the principles for ensuring that clinical trials are conducted in compliance with Good Clinical Practice (GCP) and applicable regulatory requirements. It defines Quality Assurance (QA) as all planned and systematic actions to ensure compliance with GCP and regulations during the trial and data generation. Quality Control (QC) involves operational techniques and activities to verify that quality requirements for trial-related activities are met.\\n\\nThe guideline emphasizes the sponsor\\'s responsibility to establish, implement, and maintain appropriate QA and QC processes with documented procedures. This ensures that trials are conducted and data are generated, recorded, and reported correctly. The sponsor must periodically review risk control measures to ensure their effectiveness and relevance, considering emerging knowledge and experience. Important quality issues should be summarized and reported in the clinical trial report.\\n\\nThe guideline also includes sections on risk review, risk reporting, and ethical considerations. It requires specifying data collection methods and identifying data to be recorded directly into data acquisition tools as source records. Additionally, it addresses critical-to-quality factors, associated risks, and risk mitigation strategies, as well as monitoring approaches for quality control.\\n\\nISREL: Relevant\\n\\nISSUP: Fully Supported\\n\\nISUSE: 5\\n\\n<|END'], 'segment_count': 1, 'finish_generation': True, 'critique_score': 5.0, 'retrieved_docs': [Document(id='7908cddc-7be4-46e8-b8dd-1109af8da414', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 84, 'chunk_id': 'P84-T0'}, page_content='ICH E6(R3) Guideline \\n \\n77 \\n \\nQuality Assurance (QA) \\n \\nAll those planned and systematic actions that are established to ensure that the trial is performed \\nand the data are generated, documented (recorded) and reported in compliance with GCP and \\nthe applicable regulatory requirement(s). \\n \\nQuality Control (QC) \\n \\nThe operational techniques and activities undertaken to verify that the requirements for quality \\nof the trial-related activities have been fulfilled. \\n \\nRandomisation \\n \\nThe process of deliberately including an element of chance when assigning participants to \\ngroups that receive different treatments in order to reduce bias. \\n \\nReference Safety Information (RSI) \\n \\nContains a cumulative list of ADRs that are expected for the investigational product being \\nadministered to participants in a clinical trial. The RSI is included in the Investigator’s \\nBrochure or alternative documents according to applicable regulatory requirements. Refer to'), Document(id='33d0ab06-cc53-4d46-80bb-42bcf7069aed', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 36, 'chunk_id': 'P36-T0'}, page_content='ICH E6(R3) Guideline \\n \\n29 \\n \\n3.10.1.5 Risk Review  \\n \\nThe sponsor should periodically review risk control measures to ascertain whether the \\nimplemented quality management activities remain effective and relevant, taking into \\naccount emerging knowledge and experience. Additional risk control measures may \\nbe implemented as needed. \\n \\n3.10.1.6 Risk Reporting \\n \\nThe sponsor should summarise and report important quality issues (including \\ninstances in which acceptable ranges are exceeded, as detailed in section 3.10.1.3) and \\nthe remedial actions taken and document them in the clinical trial report (see ICH E3).  \\n \\n3.11 \\nQuality Assurance and Quality Control \\n \\nThe sponsor is responsible for establishing, implementing and maintaining \\nappropriate quality assurance and quality control processes and documented \\nprocedures to ensure that trials are conducted and data are generated, recorded and \\nreported in compliance with the protocol, GCP and the applicable regulatory \\nrequirement(s).'), Document(id='8311fdb3-701b-4698-a31d-b1e26efdee8d', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 69, 'chunk_id': 'P69-T0'}, page_content='ICH E6(R3) Guideline \\n \\n62 \\n \\nB.12 \\nQuality Control and Quality Assurance  \\n \\nB.12.1 Description of identified critical to quality factors, associated risks and risk mitigation \\nstrategies in the trial unless documented elsewhere. \\n \\nB.12.2 Summary of the monitoring approaches that are part of the quality control process for \\nthe clinical trial. \\n \\nB.12.3 Description of the process for the handling of noncompliance with the protocol or \\nGCP. \\n \\nB.13 \\nEthics  \\n \\nDescription of ethical considerations relating to the trial.  \\n \\nB.14 \\nData Handling and Record Keeping  \\n \\nB.14.1 Specification of data to be collected and the method of its collection. Where necessary, \\nadditional details should be contained in a clinical trial-related document.  \\n \\nB.14.2 The identification of data to be recorded directly into the data acquisition tools (i.e., \\nno prior written or electronic record of data) and considered to be the source record.'), Document(id='8d26d7ee-6b6a-4d98-9fd4-f0cd145d7f51', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 3, 'chunk_id': 'P3-T0'}, page_content='ICH E6(R3) Guideline \\n \\ni \\n \\nICH HARMONISED GUIDELINE \\nGUIDELINE FOR GOOD CLINICAL PRACTICE \\nE6(R3) \\nICH Consensus Guideline \\nTABLE OF CONTENTS \\nI. \\nINTRODUCTION........................................................................................................ 1 \\nGuideline Scope ......................................................................................................................... 1 \\nGuideline Structure .................................................................................................................... 1 \\nII. \\nPRINCIPLES OF ICH GCP ....................................................................................... 2 \\nIII. \\nANNEX 1 ...................................................................................................................... 7 \\n1. \\nINSTITUTIONAL REVIEW BOARD/INDEPENDENT ETHICS \\nCOMMITTEE (IRB/IEC) ........................................................................................... 7 \\n1.1'), Document(id='7a470ca1-74f8-4dec-bca6-2d770a96b517', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 1, 'chunk_id': 'P1-T0'}, page_content='INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL \\nREQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE \\n \\n \\n \\nICH HARMONISED GUIDELINE \\nGUIDELINE FOR GOOD CLINICAL PRACTICE \\nE6(R3) \\n \\n \\nFinal version  \\nAdopted on 06 January 2025 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis Guideline has been developed by the appropriate ICH Expert Working Group and has been \\nsubject to consultation by the regulatory parties, in accordance with the ICH Process. At Step 4 \\nof the Process the final draft is recommended for adoption to the regulatory bodies of ICH regions.')]}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "## Segment 1:\n",
      "\n",
      "The ICH E6(R3) guideline outlines the principles for ensuring that clinical trials are conducted in compliance with Good Clinical Practice (GCP) and applicable regulatory requirements. It defines Quality Assurance (QA) as all planned and systematic actions to ensure compliance with GCP and regulations during the trial and data generation. Quality Control (QC) involves operational techniques and activities to verify that quality requirements for trial-related activities are met.\n",
      "\n",
      "The guideline emphasizes the sponsor's responsibility to establish, implement, and maintain appropriate QA and QC processes with documented procedures. This ensures that trials are conducted and data are generated, recorded, and reported correctly. The sponsor must periodically review risk control measures to ensure their effectiveness and relevance, considering emerging knowledge and experience. Important quality issues should be summarized and reported in the clinical trial report.\n",
      "\n",
      "The guideline also includes sections on risk review, risk reporting, and ethical considerations. It requires specifying data collection methods and identifying data to be recorded directly into data acquisition tools as source records. Additionally, it addresses critical-to-quality factors, associated risks, and risk mitigation strategies, as well as monitoring approaches for quality control.\n",
      "\n",
      "ISREL: Relevant\n",
      "\n",
      "ISSUP: Fully Supported\n",
      "\n",
      "ISUSE: 5\n",
      "\n",
      "<|END\n",
      "{'finalize_answer': {'query': 'What does the ICH ER6 guideline say about Quality Assurance and Quality Control?', 'retrieved_docs': [Document(id='7908cddc-7be4-46e8-b8dd-1109af8da414', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 84, 'chunk_id': 'P84-T0'}, page_content='ICH E6(R3) Guideline \\n \\n77 \\n \\nQuality Assurance (QA) \\n \\nAll those planned and systematic actions that are established to ensure that the trial is performed \\nand the data are generated, documented (recorded) and reported in compliance with GCP and \\nthe applicable regulatory requirement(s). \\n \\nQuality Control (QC) \\n \\nThe operational techniques and activities undertaken to verify that the requirements for quality \\nof the trial-related activities have been fulfilled. \\n \\nRandomisation \\n \\nThe process of deliberately including an element of chance when assigning participants to \\ngroups that receive different treatments in order to reduce bias. \\n \\nReference Safety Information (RSI) \\n \\nContains a cumulative list of ADRs that are expected for the investigational product being \\nadministered to participants in a clinical trial. The RSI is included in the Investigator’s \\nBrochure or alternative documents according to applicable regulatory requirements. Refer to'), Document(id='33d0ab06-cc53-4d46-80bb-42bcf7069aed', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 36, 'chunk_id': 'P36-T0'}, page_content='ICH E6(R3) Guideline \\n \\n29 \\n \\n3.10.1.5 Risk Review  \\n \\nThe sponsor should periodically review risk control measures to ascertain whether the \\nimplemented quality management activities remain effective and relevant, taking into \\naccount emerging knowledge and experience. Additional risk control measures may \\nbe implemented as needed. \\n \\n3.10.1.6 Risk Reporting \\n \\nThe sponsor should summarise and report important quality issues (including \\ninstances in which acceptable ranges are exceeded, as detailed in section 3.10.1.3) and \\nthe remedial actions taken and document them in the clinical trial report (see ICH E3).  \\n \\n3.11 \\nQuality Assurance and Quality Control \\n \\nThe sponsor is responsible for establishing, implementing and maintaining \\nappropriate quality assurance and quality control processes and documented \\nprocedures to ensure that trials are conducted and data are generated, recorded and \\nreported in compliance with the protocol, GCP and the applicable regulatory \\nrequirement(s).'), Document(id='8311fdb3-701b-4698-a31d-b1e26efdee8d', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 69, 'chunk_id': 'P69-T0'}, page_content='ICH E6(R3) Guideline \\n \\n62 \\n \\nB.12 \\nQuality Control and Quality Assurance  \\n \\nB.12.1 Description of identified critical to quality factors, associated risks and risk mitigation \\nstrategies in the trial unless documented elsewhere. \\n \\nB.12.2 Summary of the monitoring approaches that are part of the quality control process for \\nthe clinical trial. \\n \\nB.12.3 Description of the process for the handling of noncompliance with the protocol or \\nGCP. \\n \\nB.13 \\nEthics  \\n \\nDescription of ethical considerations relating to the trial.  \\n \\nB.14 \\nData Handling and Record Keeping  \\n \\nB.14.1 Specification of data to be collected and the method of its collection. Where necessary, \\nadditional details should be contained in a clinical trial-related document.  \\n \\nB.14.2 The identification of data to be recorded directly into the data acquisition tools (i.e., \\nno prior written or electronic record of data) and considered to be the source record.'), Document(id='8d26d7ee-6b6a-4d98-9fd4-f0cd145d7f51', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 3, 'chunk_id': 'P3-T0'}, page_content='ICH E6(R3) Guideline \\n \\ni \\n \\nICH HARMONISED GUIDELINE \\nGUIDELINE FOR GOOD CLINICAL PRACTICE \\nE6(R3) \\nICH Consensus Guideline \\nTABLE OF CONTENTS \\nI. \\nINTRODUCTION........................................................................................................ 1 \\nGuideline Scope ......................................................................................................................... 1 \\nGuideline Structure .................................................................................................................... 1 \\nII. \\nPRINCIPLES OF ICH GCP ....................................................................................... 2 \\nIII. \\nANNEX 1 ...................................................................................................................... 7 \\n1. \\nINSTITUTIONAL REVIEW BOARD/INDEPENDENT ETHICS \\nCOMMITTEE (IRB/IEC) ........................................................................................... 7 \\n1.1'), Document(id='7a470ca1-74f8-4dec-bca6-2d770a96b517', metadata={'source': 'ICH_E6(R3)_Guideline.pdf', 'page': 1, 'chunk_id': 'P1-T0'}, page_content='INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL \\nREQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE \\n \\n \\n \\nICH HARMONISED GUIDELINE \\nGUIDELINE FOR GOOD CLINICAL PRACTICE \\nE6(R3) \\n \\n \\nFinal version  \\nAdopted on 06 January 2025 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis Guideline has been developed by the appropriate ICH Expert Working Group and has been \\nsubject to consultation by the regulatory parties, in accordance with the ICH Process. At Step 4 \\nof the Process the final draft is recommended for adoption to the regulatory bodies of ICH regions.')], 'generation_history': ['\"\"\"\\n\\n\\n## Segment 1:\\n\\nThe ICH E6(R3) guideline outlines the principles for ensuring that clinical trials are conducted in compliance with Good Clinical Practice (GCP) and applicable regulatory requirements. It defines Quality Assurance (QA) as all planned and systematic actions to ensure compliance with GCP and regulations during the trial and data generation. Quality Control (QC) involves operational techniques and activities to verify that quality requirements for trial-related activities are met.\\n\\nThe guideline emphasizes the sponsor\\'s responsibility to establish, implement, and maintain appropriate QA and QC processes with documented procedures. This ensures that trials are conducted and data are generated, recorded, and reported correctly. The sponsor must periodically review risk control measures to ensure their effectiveness and relevance, considering emerging knowledge and experience. Important quality issues should be summarized and reported in the clinical trial report.\\n\\nThe guideline also includes sections on risk review, risk reporting, and ethical considerations. It requires specifying data collection methods and identifying data to be recorded directly into data acquisition tools as source records. Additionally, it addresses critical-to-quality factors, associated risks, and risk mitigation strategies, as well as monitoring approaches for quality control.\\n\\nISREL: Relevant\\n\\nISSUP: Fully Supported\\n\\nISUSE: 5\\n\\n<|END'], 'critique_score': 5.0, 'segment_count': 1, 'finish_generation': True}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "\n",
      "\n",
      "#####################################################\n",
      "           ✅ FINAL SELF-RAG ANSWER ✅                 \n",
      "#####################################################\n",
      "\n",
      "--- ANSWER ---\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "## Segment 1:\n",
      "\n",
      "The ICH E6(R3) guideline outlines the principles for ensuring that clinical trials are conducted in compliance with Good Clinical Practice (GCP) and applicable regulatory requirements. It defines Quality Assurance (QA) as all planned and systematic actions to ensure compliance with GCP and regulations during the trial and data generation. Quality Control (QC) involves operational techniques and activities to verify that quality requirements for trial-related activities are met.\n",
      "\n",
      "The guideline emphasizes the sponsor's responsibility to establish, implement, and maintain appropriate QA and QC processes with documented procedures. This ensures that trials are conducted and data are generated, recorded, and reported correctly. The sponsor must periodically review risk control measures to ensure their effectiveness and relevance, considering emerging knowledge and experience. Important quality issues should be summarized and reported in the clinical trial report.\n",
      "\n",
      "The guideline also includes sections on risk review, risk reporting, and ethical considerations. It requires specifying data collection methods and identifying data to be recorded directly into data acquisition tools as source records. Additionally, it addresses critical-to-quality factors, associated risks, and risk mitigation strategies, as well as monitoring approaches for quality control.\n",
      "\n",
      "ISREL: Relevant\n",
      "\n",
      "ISSUP: Fully Supported\n",
      "\n",
      "ISUSE: 5\n",
      "\n",
      "#####################################################\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define the query and inputs for the graph execution\n",
    "user_query = \"What does the ICH ER6 guideline say about Quality Assurance and Quality Control?\"\n",
    "inputs = {\"query\": user_query, \"generation_history\": []}\n",
    "\n",
    "# 2. Rerun stream and capture the final state\n",
    "print(\"--- Rerunning stream to answer the new query ---\", flush=True)\n",
    "\n",
    "final_state = None\n",
    "# This loop runs the graph and prints the state update after each node completes.\n",
    "for step in app.stream(inputs):\n",
    "    print(step, flush=True)\n",
    "    print(\"\\n--- NODE TRANSITION ---\\n\", flush=True)\n",
    "    # Capture the last yielded state (which contains the compiled final history)\n",
    "    for key, value in step.items():\n",
    "        if key != END:\n",
    "            final_state = value\n",
    "\n",
    "# 3. Extract and Format the Final Answer\n",
    "if final_state and \"generation_history\" in final_state:\n",
    "    # Join all generated segments (which should now be clean)\n",
    "    final_answer_text = \"\\n\".join(final_state[\"generation_history\"]).strip()\n",
    "    \n",
    "    # Run a final cleanup pass\n",
    "    final_answer_text = re.sub(r'\\s*(Relevant|Irrelevant)\\s*(Fully Supported|Partially Supported|No Support)\\s*\\d', '', final_answer_text).strip()\n",
    "    final_answer_text = final_answer_text.replace(\"<|END\", \"\").strip()\n",
    "\n",
    "    # 4. Present the Results\n",
    "    print(\"\\n\\n#####################################################\", flush=True)\n",
    "    print(\"            FINAL SELF-RAG ANSWER                 \", flush=True)\n",
    "    print(\"#####################################################\\n\", flush=True)\n",
    "\n",
    "    print(\"--- ANSWER ---\", flush=True)\n",
    "    print(final_answer_text, flush=True)\n",
    "    print(\"\\n#####################################################\", flush=True)\n",
    "\n",
    "else:\n",
    "    print(\"\\n EXECUTION FAILED or final state was not captured.\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c37622cb-9560-4fe7-82ed-e8581c311c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Rerunning stream to answer the new combined query ---\n",
      "Decision: Retrieval required.\n",
      "{'initial_decision': {'query': 'According to EFPIA 2024 data on multiple inspections at manufacturing sites, which countries recorded the highest inspection counts per site, and what does this reveal about their regulatory significance?', 'retrieved_docs': [], 'critique_score': 0.0, 'segment_count': 0, 'finish_generation': False}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "Retrieving documents for: 'According to EFPIA 2024 data on multiple inspectio...'\n",
      "{'retrieve_docs': {'retrieved_docs': [Document(id='6f221e35-3bae-4e4d-a47f-8e6df714b254', metadata={'source': 'inspection_survey.pdf', 'page': 44, 'chunk_id': 'P44-T0'}, page_content='44\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nMultiple inspections at one manufacturing site (6 and more)\\nINSPECTIONS AT MANUFACTURING SITES\\n.\\n.\\nUS\\n• AMA\\n• Tanzania\\n• Brazil\\n• Russia\\n• Türkiye\\nGermany\\n• US-FDA (2)\\n• Belarus\\n• Türkiye\\nFrance\\n• US-FDA\\n• Türkiye\\n• Rep. of Korea\\n• China\\n• EAEU\\nDenmark\\n• Japan (4)\\n• Brazil (2)\\n• US-FDA\\n• Türkiye\\n• Kenya\\n• Chinese Taipei\\n• Rep. of Korea\\nGermany\\n• Japan\\n• Türkiye\\n• Belarus\\nGermany\\n• China\\n• Russia\\n• Türkiye\\n• Libya\\nUS\\n• Japan\\nGermany\\n• Russia\\nDenmark\\n• Japan (3)\\n• Rep. of Korea (3)\\n• Brazil \\n• Chinese Taipei\\n• Türkiye\\n• Kenya\\nBrazil\\n• Mexico\\nMost sites exposed to multiple foreign \\ninspections are in Germany (4) and Denmark (2)'), Document(id='ca2bdd03-24e9-4ff7-bb79-1e94ef40bd87', metadata={'source': 'inspection_survey.pdf', 'page': 5, 'chunk_id': 'P5-T0'}, page_content='5\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nNumber of foreign inspections at manufacturing sites \\n(EU as one entity; all inspection types and modes)\\nEFPIA’S ANNUAL INSPECTION SURVEY - DATA\\n> 28\\n*Inspectorate is a PIC/S participating authority   **PIC/S Applicant     ***PIC/S Pre-Applicant\\nPerformed by\\n\\uf0b3 9\\n+ 9 countries with one  foreign inspection\\n[same level as last years]'), Document(id='695b6077-e2cc-46a7-929f-22e68f24c037', metadata={'source': 'inspection_survey.pdf', 'page': 9, 'chunk_id': 'P9-T0'}, page_content='9\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nOversight\\n80% of foreign inspections are in EU/EEA, US and Switzerland; \\nthis demonstrates where research-based industry is manufacturing \\nEU/EEA (50%), US (27%), Switzerland (5%), China (4%), Singapore (3%), \\nand Brazil (3%)\\nFor the EU/EEA it’s mainly in Germany, France, Belgium, Denmark, \\nIreland, Italy\\nSites most exposed to multiple foreign inspections are in Germany (4) \\nand Denmark (2)\\nNumber of foreign inspections at manufacturing sites post pandemic is \\nslightly decreasing to the baseline before the pandemic\\nIndividual sites receive more foreign inspections - higher than before the \\npandemic and highest ever\\nForeign inspections at manufacturing sites\\nEFPIA’S ANNUAL INSPECTION SURVEY - DATA\\nManufacturing'), Document(id='36885416-d5ff-49cf-84e8-de7320c30d56', metadata={'source': 'inspection_survey.pdf', 'page': 50, 'chunk_id': 'P50-T0'}, page_content='50\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nChina, EU / EEA, Japan, US, Pakistan and Brazil are the countries with the \\nmost inspections by sites for local / regional supply \\nInspections in country at sites reported for \\ndomestic or regional supply only – several years history\\nINSPECTIONS AT MANUFACTURING SITES - SUPPLY'), Document(id='1d87fb73-27c4-4f08-aee5-66d5a74e8a04', metadata={'source': 'inspection_survey.pdf', 'page': 59, 'chunk_id': 'P59-T0'}, page_content='59\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEven if FDA is doing announced foreign inspection companies report to have \\nmore inspections with follow up in 3rd countries than for sites in the US\\nRate of inspections with follow-up actions\\nINSPECTIONS AT MANUFACTURING SITES')]}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "Generating Segment 1...\n",
      "  -> ISREL: Relevant, ISSUP: Fully Supported, ISUSE: 5\n",
      "{'generate_segment': {'generation_history': ['SEGMENT:\\nThe countries with the highest inspection counts per manufacturing site, according to the EFPIA 2024 data, are Germany and Denmark, each with four multiple inspections at their sites. This indicates significant regulatory scrutiny and importance in the pharmaceutical manufacturing sector. Germany stands out with additional sites also facing inspections from Belarus, Türkiye, Russia, and the US-FDA, while Denmark has inspections from Japan, Brazil, US-FDA, Türkiye, Kenya, Chinese Taipei, and the Rep. of Korea. The high number of inspections suggests that these countries play crucial roles in global pharmaceutical manufacturing oversight, likely due to their central positions in the industry and stringent regulatory environments.\\n\\nISREL: Relevant\\nISSUP: Fully Supported\\nISUSE: 5\\n\\n<|END'], 'segment_count': 1, 'finish_generation': True, 'critique_score': 5.0, 'retrieved_docs': [Document(id='6f221e35-3bae-4e4d-a47f-8e6df714b254', metadata={'source': 'inspection_survey.pdf', 'page': 44, 'chunk_id': 'P44-T0'}, page_content='44\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nMultiple inspections at one manufacturing site (6 and more)\\nINSPECTIONS AT MANUFACTURING SITES\\n.\\n.\\nUS\\n• AMA\\n• Tanzania\\n• Brazil\\n• Russia\\n• Türkiye\\nGermany\\n• US-FDA (2)\\n• Belarus\\n• Türkiye\\nFrance\\n• US-FDA\\n• Türkiye\\n• Rep. of Korea\\n• China\\n• EAEU\\nDenmark\\n• Japan (4)\\n• Brazil (2)\\n• US-FDA\\n• Türkiye\\n• Kenya\\n• Chinese Taipei\\n• Rep. of Korea\\nGermany\\n• Japan\\n• Türkiye\\n• Belarus\\nGermany\\n• China\\n• Russia\\n• Türkiye\\n• Libya\\nUS\\n• Japan\\nGermany\\n• Russia\\nDenmark\\n• Japan (3)\\n• Rep. of Korea (3)\\n• Brazil \\n• Chinese Taipei\\n• Türkiye\\n• Kenya\\nBrazil\\n• Mexico\\nMost sites exposed to multiple foreign \\ninspections are in Germany (4) and Denmark (2)'), Document(id='ca2bdd03-24e9-4ff7-bb79-1e94ef40bd87', metadata={'source': 'inspection_survey.pdf', 'page': 5, 'chunk_id': 'P5-T0'}, page_content='5\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nNumber of foreign inspections at manufacturing sites \\n(EU as one entity; all inspection types and modes)\\nEFPIA’S ANNUAL INSPECTION SURVEY - DATA\\n> 28\\n*Inspectorate is a PIC/S participating authority   **PIC/S Applicant     ***PIC/S Pre-Applicant\\nPerformed by\\n\\uf0b3 9\\n+ 9 countries with one  foreign inspection\\n[same level as last years]'), Document(id='695b6077-e2cc-46a7-929f-22e68f24c037', metadata={'source': 'inspection_survey.pdf', 'page': 9, 'chunk_id': 'P9-T0'}, page_content='9\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nOversight\\n80% of foreign inspections are in EU/EEA, US and Switzerland; \\nthis demonstrates where research-based industry is manufacturing \\nEU/EEA (50%), US (27%), Switzerland (5%), China (4%), Singapore (3%), \\nand Brazil (3%)\\nFor the EU/EEA it’s mainly in Germany, France, Belgium, Denmark, \\nIreland, Italy\\nSites most exposed to multiple foreign inspections are in Germany (4) \\nand Denmark (2)\\nNumber of foreign inspections at manufacturing sites post pandemic is \\nslightly decreasing to the baseline before the pandemic\\nIndividual sites receive more foreign inspections - higher than before the \\npandemic and highest ever\\nForeign inspections at manufacturing sites\\nEFPIA’S ANNUAL INSPECTION SURVEY - DATA\\nManufacturing'), Document(id='36885416-d5ff-49cf-84e8-de7320c30d56', metadata={'source': 'inspection_survey.pdf', 'page': 50, 'chunk_id': 'P50-T0'}, page_content='50\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nChina, EU / EEA, Japan, US, Pakistan and Brazil are the countries with the \\nmost inspections by sites for local / regional supply \\nInspections in country at sites reported for \\ndomestic or regional supply only – several years history\\nINSPECTIONS AT MANUFACTURING SITES - SUPPLY'), Document(id='1d87fb73-27c4-4f08-aee5-66d5a74e8a04', metadata={'source': 'inspection_survey.pdf', 'page': 59, 'chunk_id': 'P59-T0'}, page_content='59\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEven if FDA is doing announced foreign inspection companies report to have \\nmore inspections with follow up in 3rd countries than for sites in the US\\nRate of inspections with follow-up actions\\nINSPECTIONS AT MANUFACTURING SITES')]}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "\n",
      "--- FINAL ANSWER ---\n",
      "SEGMENT:\n",
      "The countries with the highest inspection counts per manufacturing site, according to the EFPIA 2024 data, are Germany and Denmark, each with four multiple inspections at their sites. This indicates significant regulatory scrutiny and importance in the pharmaceutical manufacturing sector. Germany stands out with additional sites also facing inspections from Belarus, Türkiye, Russia, and the US-FDA, while Denmark has inspections from Japan, Brazil, US-FDA, Türkiye, Kenya, Chinese Taipei, and the Rep. of Korea. The high number of inspections suggests that these countries play crucial roles in global pharmaceutical manufacturing oversight, likely due to their central positions in the industry and stringent regulatory environments.\n",
      "\n",
      "ISREL: Relevant\n",
      "ISSUP: Fully Supported\n",
      "ISUSE: 5\n",
      "\n",
      "<|END\n",
      "{'finalize_answer': {'query': 'According to EFPIA 2024 data on multiple inspections at manufacturing sites, which countries recorded the highest inspection counts per site, and what does this reveal about their regulatory significance?', 'retrieved_docs': [Document(id='6f221e35-3bae-4e4d-a47f-8e6df714b254', metadata={'source': 'inspection_survey.pdf', 'page': 44, 'chunk_id': 'P44-T0'}, page_content='44\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nMultiple inspections at one manufacturing site (6 and more)\\nINSPECTIONS AT MANUFACTURING SITES\\n.\\n.\\nUS\\n• AMA\\n• Tanzania\\n• Brazil\\n• Russia\\n• Türkiye\\nGermany\\n• US-FDA (2)\\n• Belarus\\n• Türkiye\\nFrance\\n• US-FDA\\n• Türkiye\\n• Rep. of Korea\\n• China\\n• EAEU\\nDenmark\\n• Japan (4)\\n• Brazil (2)\\n• US-FDA\\n• Türkiye\\n• Kenya\\n• Chinese Taipei\\n• Rep. of Korea\\nGermany\\n• Japan\\n• Türkiye\\n• Belarus\\nGermany\\n• China\\n• Russia\\n• Türkiye\\n• Libya\\nUS\\n• Japan\\nGermany\\n• Russia\\nDenmark\\n• Japan (3)\\n• Rep. of Korea (3)\\n• Brazil \\n• Chinese Taipei\\n• Türkiye\\n• Kenya\\nBrazil\\n• Mexico\\nMost sites exposed to multiple foreign \\ninspections are in Germany (4) and Denmark (2)'), Document(id='ca2bdd03-24e9-4ff7-bb79-1e94ef40bd87', metadata={'source': 'inspection_survey.pdf', 'page': 5, 'chunk_id': 'P5-T0'}, page_content='5\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nNumber of foreign inspections at manufacturing sites \\n(EU as one entity; all inspection types and modes)\\nEFPIA’S ANNUAL INSPECTION SURVEY - DATA\\n> 28\\n*Inspectorate is a PIC/S participating authority   **PIC/S Applicant     ***PIC/S Pre-Applicant\\nPerformed by\\n\\uf0b3 9\\n+ 9 countries with one  foreign inspection\\n[same level as last years]'), Document(id='695b6077-e2cc-46a7-929f-22e68f24c037', metadata={'source': 'inspection_survey.pdf', 'page': 9, 'chunk_id': 'P9-T0'}, page_content='9\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nOversight\\n80% of foreign inspections are in EU/EEA, US and Switzerland; \\nthis demonstrates where research-based industry is manufacturing \\nEU/EEA (50%), US (27%), Switzerland (5%), China (4%), Singapore (3%), \\nand Brazil (3%)\\nFor the EU/EEA it’s mainly in Germany, France, Belgium, Denmark, \\nIreland, Italy\\nSites most exposed to multiple foreign inspections are in Germany (4) \\nand Denmark (2)\\nNumber of foreign inspections at manufacturing sites post pandemic is \\nslightly decreasing to the baseline before the pandemic\\nIndividual sites receive more foreign inspections - higher than before the \\npandemic and highest ever\\nForeign inspections at manufacturing sites\\nEFPIA’S ANNUAL INSPECTION SURVEY - DATA\\nManufacturing'), Document(id='36885416-d5ff-49cf-84e8-de7320c30d56', metadata={'source': 'inspection_survey.pdf', 'page': 50, 'chunk_id': 'P50-T0'}, page_content='50\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nChina, EU / EEA, Japan, US, Pakistan and Brazil are the countries with the \\nmost inspections by sites for local / regional supply \\nInspections in country at sites reported for \\ndomestic or regional supply only – several years history\\nINSPECTIONS AT MANUFACTURING SITES - SUPPLY'), Document(id='1d87fb73-27c4-4f08-aee5-66d5a74e8a04', metadata={'source': 'inspection_survey.pdf', 'page': 59, 'chunk_id': 'P59-T0'}, page_content='59\\nEFPIA ANNUAL INSPECTION SURVEY - 2024 DATA - PUBLIC VERSION\\nEven if FDA is doing announced foreign inspection companies report to have \\nmore inspections with follow up in 3rd countries than for sites in the US\\nRate of inspections with follow-up actions\\nINSPECTIONS AT MANUFACTURING SITES')], 'generation_history': ['SEGMENT:\\nThe countries with the highest inspection counts per manufacturing site, according to the EFPIA 2024 data, are Germany and Denmark, each with four multiple inspections at their sites. This indicates significant regulatory scrutiny and importance in the pharmaceutical manufacturing sector. Germany stands out with additional sites also facing inspections from Belarus, Türkiye, Russia, and the US-FDA, while Denmark has inspections from Japan, Brazil, US-FDA, Türkiye, Kenya, Chinese Taipei, and the Rep. of Korea. The high number of inspections suggests that these countries play crucial roles in global pharmaceutical manufacturing oversight, likely due to their central positions in the industry and stringent regulatory environments.\\n\\nISREL: Relevant\\nISSUP: Fully Supported\\nISUSE: 5\\n\\n<|END'], 'critique_score': 5.0, 'segment_count': 1, 'finish_generation': True}}\n",
      "\n",
      "--- NODE TRANSITION ---\n",
      "\n",
      "\n",
      "\n",
      "#####################################################\n",
      "           ✅ FINAL SELF-RAG ANSWER ✅                 \n",
      "#####################################################\n",
      "\n",
      "--- ANSWER ---\n",
      "SEGMENT:\n",
      "The countries with the highest inspection counts per manufacturing site, according to the EFPIA 2024 data, are Germany and Denmark, each with four multiple inspections at their sites. This indicates significant regulatory scrutiny and importance in the pharmaceutical manufacturing sector. Germany stands out with additional sites also facing inspections from Belarus, Türkiye, Russia, and the US-FDA, while Denmark has inspections from Japan, Brazil, US-FDA, Türkiye, Kenya, Chinese Taipei, and the Rep. of Korea. The high number of inspections suggests that these countries play crucial roles in global pharmaceutical manufacturing oversight, likely due to their central positions in the industry and stringent regulatory environments.\n",
      "\n",
      "ISREL: Relevant\n",
      "ISSUP: Fully Supported\n",
      "ISUSE: 5\n",
      "\n",
      "#####################################################\n"
     ]
    }
   ],
   "source": [
    "# USER QUERY: According to EFPIA 2024 data on multiple inspections at manufacturing sites, which countries recorded the highest inspection counts per site, and what does this reveal about their regulatory significance?\n",
    "# 1. Define the query and inputs for the graph execution\n",
    "user_query = \"According to EFPIA 2024 data on multiple inspections at manufacturing sites, which countries recorded the highest inspection counts per site, and what does this reveal about their regulatory significance?\"\n",
    "inputs = {\"query\": user_query, \"generation_history\": []}\n",
    "\n",
    "# 2. Rerun stream and capture the final state\n",
    "print(\"--- Rerunning stream to answer the new combined query ---\", flush=True)\n",
    "\n",
    "final_state = None\n",
    "# This loop runs the graph and prints the state update after each node completes.\n",
    "for step in app.stream(inputs):\n",
    "    print(step, flush=True)\n",
    "    print(\"\\n--- NODE TRANSITION ---\\n\", flush=True)\n",
    "    # Capture the last yielded state (which contains the compiled final history)\n",
    "    for key, value in step.items():\n",
    "        if key != END:\n",
    "            final_state = value\n",
    "\n",
    "# 3. Extract and Format the Final Answer\n",
    "if final_state and \"generation_history\" in final_state:\n",
    "    # Join all generated segments (which should now be clean)\n",
    "    final_answer_text = \"\\n\".join(final_state[\"generation_history\"]).strip()\n",
    "    \n",
    "    # Run a final cleanup pass\n",
    "    final_answer_text = re.sub(r'\\s*(Relevant|Irrelevant)\\s*(Fully Supported|Partially Supported|No Support)\\s*\\d', '', final_answer_text).strip()\n",
    "    final_answer_text = final_answer_text.replace(\"<|END\", \"\").strip()\n",
    "\n",
    "    # 4. Present the Results\n",
    "    print(\"\\n\\n#####################################################\", flush=True)\n",
    "    print(\"            FINAL SELF-RAG ANSWER                  \", flush=True)\n",
    "    print(\"#####################################################\\n\", flush=True)\n",
    "\n",
    "    print(\"--- ANSWER ---\", flush=True)\n",
    "    print(final_answer_text, flush=True)\n",
    "    print(\"\\n#####################################################\", flush=True)\n",
    "\n",
    "else:\n",
    "    print(\"\\n EXECUTION FAILED or final state was not captured.\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The self-reflective retrieval augmented generation setup in this tutorial offers major advantages over standard RAG, mainly in terms of reliability and smart efficiency. Its biggest strength is improved factual accuracy and traceability, made possible by the Granite LLM running its own self-critiques with reflection tokens. These critiques produce a score that guides the workflow, allowing adaptive retrieval and the model only pulls new context when a segment isn’t well supported. This approach also makes it easier to work with complex, multi-modal documents, since image captions can be added to the vector store. The result is a more trustworthy, flexible query agent that checks and segments its answers against the knowledge base before giving the final result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
